#!/usr/bin/env python3
"""
pair_designer_v3.py â€” KG ìê°€ ìµœì í™” ì—”ì§„ v3 (CSER ì œì•½ + êµì°¨ì¶œì²˜ ë³´ë„ˆìŠ¤)

ì‚¬ì´í´ 59, n-150 ì„¤ê³„ê²°í•¨ ë¶„ì„ â†’ v3 êµ¬í˜„.

v2 â†’ v3 í•µì‹¬ ë³€ê²½:
  1. cross_source_bonus = +0.30
     - ë¡ì´â†”cokac êµì°¨ ìŒì— 0.30 ê°€ì‚°ì 
     - semantic_score ë™ì¼ì¶œì²˜ ìš°ìœ„ ì—­ì „ (D-033: ê²½ê³„ íš¡ë‹¨ = ì°½ë°œ)

  2. CSER >= 0.65 ì œì•½ (ì‹ ê·œ)
     - ì—£ì§€ ì¶”ê°€ í›„ CSER ìœ ì§€ ë³´ì¥
     - ë™ì¼ì¶œì²˜ ì—£ì§€ê°€ CSER ì ì‹í•˜ë©´ ì„ íƒì—ì„œ ì œì™¸

  3. 4ì°¨ì› ëª©í‘œí•¨ìˆ˜:
       max(E_v4) subject to:
         CSER >= 0.65          â† ì‹ ê·œ ì œì•½
         0.15 < distance < 0.30   (distance = span_score = span / max_node_id)
         1.20 < asymmetry < 2.50  (asymmetry = span_score / semantic_score)

  4. min_semantic í•˜í–¥: 0.25 â†’ 0.05
     - êµì°¨ì¶œì²˜ ìŒì€ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ê°€ ë‚®ìŒ. cross_bonusë¡œ ë³´ì™„.

v2 ì„¤ê³„ê²°í•¨ (n-150):
  semantic_scoreê°€ ë™ì¼ì¶œì²˜ ìŒ(ë¡ì´â†’ë¡ì´)ì„ ì„ í˜¸.
  cross_source_bonus ì—†ì´ëŠ” D-033(ê²½ê³„ íš¡ë‹¨=ì°½ë°œ) ìœ„ë°˜.

4D ì œì•½ ì„¤ê³„ ì›ë¦¬:
  - distance = span_score: ì‹œê°„ì  ê±°ë¦¬. ë„ˆë¬´ ê°€ê¹Œìš°ë©´ local, ë„ˆë¬´ ë©€ë©´ forced.
  - asymmetry = span_score / semantic_score: ì‹œê°„ ê±°ë¦¬ ëŒ€ë¹„ ì˜ë¯¸ ì°¨ì´ ë¹„ìœ¨.
    ë†’ì„ìˆ˜ë¡ "ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ë‹¤ë¥¸ë° ì‹œê°„ì ìœ¼ë¡œ ê°€ê¹Œìš´" ì—°ê²°.
    1.20~2.50ì´ "êµì°¨ì¶œì²˜ ìì—° ì—°ê²°" êµ¬ê°„.
    ë™ì¼ì¶œì²˜ ìŒì€ semantic_scoreê°€ ë†’ì•„ asymmetryê°€ ë‚®ì•„ì§ â†’ ìì—° í•„í„°.

ì‚¬ìš©ë²•:
  python3 src/pair_designer_v3.py              # ìƒìœ„ 20ê°œ ì¶”ì²œ
  python3 src/pair_designer_v3.py --top 15     # ìƒìœ„ 15ê°œ
  python3 src/pair_designer_v3.py --json       # JSON ì¶œë ¥
  python3 src/pair_designer_v3.py --add N      # KGì— ì¶”ê°€ + E_v4 ì¸¡ì •
  python3 src/pair_designer_v3.py --soft       # 4D ì†Œí”„íŠ¸ ëª¨ë“œ (ì œì•½ ìœ„ë°˜ í—ˆìš©, í˜ë„í‹°ë§Œ)
  python3 src/pair_designer_v3.py --verify     # ë§ˆì§€ë§‰ ì¶”ê°€ ê²°ê³¼ ì¶œë ¥
  python3 src/pair_designer_v3.py --source-stats  # êµì°¨ì¶œì²˜ í†µê³„

êµ¬í˜„: cokac-bot (ì‚¬ì´í´ 60)
"""

import json
import re
import sys
import statistics
from pathlib import Path
from datetime import date
from itertools import combinations

REPO = Path(__file__).parent.parent
KG_FILE = REPO / "data" / "knowledge-graph.json"
RESULT_FILE = REPO / "data" / "pair_designer_v3_log.json"

VERSION = "v3"
CYCLE = 60

# â”€â”€â”€ v3 í•µì‹¬ ìƒìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ë¡ì´â†”cokac êµì°¨ ìŒ ê°€ì‚°ì  (D-033: ê²½ê³„ íš¡ë‹¨ = ì°½ë°œ)
CROSS_SOURCE_BONUS = 0.30

# CSER í•˜í•œ ì œì•½ (ì‹ ê·œ)
CSER_MIN = 0.65

# 4ì°¨ì› ëª©í‘œí•¨ìˆ˜ ì œì•½ ë²”ìœ„
DISTANCE_MIN = 0.15   # span_score í•˜í•œ
DISTANCE_MAX = 0.30   # span_score ìƒí•œ
ASYMMETRY_MIN = 1.20  # span_score / semantic_score í•˜í•œ
ASYMMETRY_MAX = 2.50  # span_score / semantic_score ìƒí•œ

# DCI feeding ê´€ê³„ â€” v2 ì •ì±… ìœ ì§€
DCI_FEEDING_RELATIONS = {"answers", "addresses"}
MAX_DCI_DELTA_PER_EDGE = 0.0001

# êµì°¨ì¶œì²˜ íŒ€ ë¶„ë¥˜
LOKI_SOURCES = {"ë¡ì´", "ìƒë¡"}
COKAC_SOURCES = {"cokac", "cokac-bot"}

# â”€â”€â”€ íƒ€ì… í˜¸í™˜ì„± í–‰ë ¬ (v2 ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TYPE_COMPAT = {
    ("insight",     "question"):    0.85,
    ("observation", "question"):    0.80,
    ("prediction",  "question"):    0.75,
    ("prediction",  "observation"): 0.90,
    ("prediction",  "insight"):     0.70,
    ("insight",     "insight"):     0.60,
    ("insight",     "observation"): 0.65,
    ("insight",     "decision"):    0.72,
    ("decision",    "observation"): 0.65,
    ("decision",    "question"):    0.68,
    ("observation", "observation"): 0.45,
    ("insight",     "experiment"):  0.75,
    ("observation", "experiment"):  0.80,
    ("prediction",  "experiment"):  0.85,
    ("question",    "experiment"):  0.70,
    ("concept",     "insight"):     0.65,
    ("concept",     "observation"): 0.60,
    ("concept",     "question"):    0.65,
    ("finding",     "insight"):     0.75,
    ("finding",     "prediction"):  0.70,
    ("finding",     "observation"): 0.72,
    ("synthesis",   "insight"):     0.80,
    ("synthesis",   "observation"): 0.75,
    ("artifact",    "insight"):     0.55,
    ("artifact",    "experiment"):  0.65,
    ("tool",        "experiment"):  0.70,
    ("tool",        "artifact"):    0.60,
    ("persona",     "observation"): 0.55,
    ("persona",     "insight"):     0.50,
}
DEFAULT_COMPAT = 0.30

# â”€â”€â”€ DCI ì¤‘ë¦½ ê´€ê³„ íŒíŠ¸ (v2 ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RELATION_HINT = {
    ("insight",     "question"):    ("resonates_with", "ì¸ì‚¬ì´íŠ¸ê°€ ì§ˆë¬¸ê³¼ ê³µëª…í•œë‹¤"),
    ("observation", "question"):    ("contextualizes", "ê´€ì°°ì´ ì§ˆë¬¸ì˜ ë§¥ë½ì„ ì œê³µí•œë‹¤"),
    ("prediction",  "question"):    ("parallel_to",    "ì˜ˆì¸¡ì´ ì§ˆë¬¸ê³¼ ë³‘ë ¬ë¡œ ì „ê°œëœë‹¤"),
    ("prediction",  "observation"): ("validated_by",   "ê´€ì°°ì´ ì˜ˆì¸¡ì„ ê²€ì¦í•œë‹¤"),
    ("prediction",  "insight"):     ("informed_by",    "ì˜ˆì¸¡ì´ ì¸ì‚¬ì´íŠ¸ì— ê·¼ê±°í•œë‹¤"),
    ("insight",     "insight"):     ("extends",        "ì¸ì‚¬ì´íŠ¸ê°€ ë‹¤ë¥¸ ì¸ì‚¬ì´íŠ¸ë¥¼ í™•ì¥í•œë‹¤"),
    ("insight",     "observation"): ("grounds",        "ì¸ì‚¬ì´íŠ¸ê°€ ê´€ì°°ì— ê·¼ê±°í•œë‹¤"),
    ("insight",     "decision"):    ("supports",       "ì¸ì‚¬ì´íŠ¸ê°€ ê²°ì •ì„ ì§€ì§€í•œë‹¤"),
    ("observation", "experiment"):  ("evidence_for",   "ê´€ì°°ì´ ì‹¤í—˜ ì¦ê±°ê°€ ëœë‹¤"),
    ("prediction",  "experiment"):  ("tested_by",      "ì˜ˆì¸¡ì´ ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦ëœë‹¤"),
    ("finding",     "insight"):     ("generalizes",    "ë°œê²¬ì´ ì¸ì‚¬ì´íŠ¸ë¡œ ì¼ë°˜í™”ëœë‹¤"),
    ("synthesis",   "insight"):     ("synthesizes",    "í•©ì„±ì´ ì¸ì‚¬ì´íŠ¸ë¥¼ í†µí•©í•œë‹¤"),
    ("concept",     "insight"):     ("resonates_with", "ê°œë…ì´ ì¸ì‚¬ì´íŠ¸ì™€ ê³µëª…í•œë‹¤"),
    ("concept",     "question"):    ("parallel_to",    "ê°œë…ì´ ì§ˆë¬¸ê³¼ ë³‘ë ¬ë¡œ íƒêµ¬ëœë‹¤"),
    ("finding",     "prediction"):  ("extends",        "ë°œê²¬ì´ ì˜ˆì¸¡ì„ í™•ì¥í•œë‹¤"),
    ("synthesis",   "observation"): ("grounds",        "í•©ì„±ì´ ê´€ì°°ì— ê·¼ê±°í•œë‹¤"),
}
DEFAULT_RELATION = ("relates_to", "ì˜ë¯¸ë¡ ì  ì—°ê²°")


# â”€â”€â”€ I/O â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_kg() -> dict:
    return json.loads(KG_FILE.read_text(encoding="utf-8"))


def save_kg(kg: dict) -> None:
    if "meta" not in kg:
        existing_nums = [int(n["id"].split("-")[1]) for n in kg["nodes"] if n["id"].startswith("n-")]
        next_num = (max(existing_nums) + 1) if existing_nums else 1
        kg["meta"] = {
            "next_node_id": f"n-{next_num:03d}",
            "last_updated": str(date.today()),
            "total_nodes": len(kg["nodes"]),
            "total_edges": len(kg["edges"]),
        }
    else:
        kg["meta"]["total_nodes"] = len(kg["nodes"])
        kg["meta"]["total_edges"] = len(kg["edges"])
        kg["meta"]["last_updated"] = str(date.today())
    KG_FILE.write_text(
        json.dumps(kg, ensure_ascii=False, indent=2) + "\n",
        encoding="utf-8"
    )


def load_log() -> dict:
    if RESULT_FILE.exists():
        return json.loads(RESULT_FILE.read_text(encoding="utf-8"))
    return {
        "meta": {
            "description": "pair_designer v3 ì´ë ¥ (CSER ì œì•½ + êµì°¨ì¶œì²˜ ë³´ë„ˆìŠ¤)",
            "created_cycle": CYCLE,
            "version": VERSION,
        },
        "sessions": [],
    }


def save_log(data: dict) -> None:
    RESULT_FILE.write_text(
        json.dumps(data, ensure_ascii=False, indent=2) + "\n",
        encoding="utf-8"
    )


# â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def node_num(nid: str) -> int:
    try:
        return int(nid.replace("n-", ""))
    except ValueError:
        return 0


def tokenize(text: str) -> set:
    words = re.split(r"[\s\n\r\t\u3000.,!?;:ã€Œã€ã€ã€ã€ã€‘()ï¼ˆï¼‰\-_/]+", text.lower())
    return {w for w in words if len(w) >= 2 and not w.isdigit()}


def jaccard(a: set, b: set) -> float:
    if not a and not b:
        return 0.0
    union = a | b
    return len(a & b) / len(union) if union else 0.0


def type_compat_score(t1: str, t2: str) -> float:
    key = tuple(sorted([t1, t2]))
    return TYPE_COMPAT.get(key, DEFAULT_COMPAT)


def infer_relation(t1: str, t2: str) -> tuple:
    key = tuple(sorted([t1, t2]))
    rel, label = RELATION_HINT.get(key, DEFAULT_RELATION)
    if rel in DCI_FEEDING_RELATIONS:
        return ("resonates_with", f"{t1}â†”{t2} ê³µëª…")
    return rel, label


def classify_source(source: str) -> str:
    """ì¶œì²˜ë¥¼ íŒ€ìœ¼ë¡œ ë¶„ë¥˜."""
    if source in LOKI_SOURCES:
        return "ë¡ì´"
    if source in COKAC_SOURCES:
        return "cokac"
    return "ê¸°íƒ€"


def is_cross_source(n1: dict, n2: dict) -> bool:
    """ë‘ ë…¸ë“œê°€ ë¡ì´â†”cokac êµì°¨ ì¶œì²˜ì¸ì§€ íŒë³„."""
    t1 = classify_source(n1.get("source", ""))
    t2 = classify_source(n2.get("source", ""))
    return t1 != t2 and "ê¸°íƒ€" not in (t1, t2)


# â”€â”€â”€ CSER ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compute_cser_raw(kg: dict) -> tuple:
    """(cross_count, total_count) ë°˜í™˜."""
    node_src = {n["id"]: n.get("source", "") for n in kg["nodes"]}
    cross = sum(
        1 for e in kg["edges"]
        if node_src.get(e["from"], "") != node_src.get(e["to"], "")
    )
    return cross, len(kg["edges"])


def simulate_cser(kg: dict, new_pairs: list) -> float:
    """
    new_pairs: [(from_id, to_id, is_cross_source), ...] ì¶”ê°€ í›„ CSER ì˜ˆì¸¡.
    """
    node_src = {n["id"]: n.get("source", "") for n in kg["nodes"]}
    cross_now, total_now = compute_cser_raw(kg)

    add_cross = sum(
        1 for (fid, tid, _) in new_pairs
        if node_src.get(fid, "") != node_src.get(tid, "")
    )
    total_new = total_now + len(new_pairs)
    if total_new == 0:
        return 0.0
    return round((cross_now + add_cross) / total_new, 4)


# â”€â”€â”€ 4ì°¨ì› ì œì•½ ê²€ì‚¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def check_4d(span_score: float, semantic_score: float) -> tuple:
    """
    4D ì œì•½ ê²€ì‚¬.
    ë°˜í™˜: (passes: bool, distance: float, asymmetry: float, reason: str)

    distance  = span_score
    asymmetry = span_score / (semantic_score + eps)
    """
    distance = span_score
    eps = 0.001
    asymmetry = span_score / (semantic_score + eps)

    if not (DISTANCE_MIN < distance < DISTANCE_MAX):
        return False, distance, asymmetry, f"distance {distance:.3f} âˆ‰ ({DISTANCE_MIN},{DISTANCE_MAX})"
    if not (ASYMMETRY_MIN < asymmetry < ASYMMETRY_MAX):
        return False, distance, asymmetry, f"asymmetry {asymmetry:.3f} âˆ‰ ({ASYMMETRY_MIN},{ASYMMETRY_MAX})"
    return True, distance, asymmetry, "OK"


# â”€â”€â”€ í•µì‹¬: ì ìˆ˜ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def score_pair(n1: dict, n2: dict, max_node_id: int) -> dict:
    id1 = node_num(n1["id"])
    id2 = node_num(n2["id"])
    span = abs(id1 - id2)
    span_score = span / max_node_id if max_node_id > 0 else 0.0

    tags1 = set(n1.get("tags", []))
    tags2 = set(n2.get("tags", []))
    tag_sim = jaccard(tags1, tags2)

    t_compat = type_compat_score(n1.get("type", ""), n2.get("type", ""))

    content1 = tokenize(n1.get("content", "") + " " + n1.get("label", ""))
    content2 = tokenize(n2.get("content", "") + " " + n2.get("label", ""))
    content_sim = jaccard(content1, content2)

    semantic_score = 0.40 * tag_sim + 0.35 * t_compat + 0.25 * content_sim

    cross = is_cross_source(n1, n2)
    passes_4d, distance, asymmetry, reason = check_4d(span_score, semantic_score)

    relation, _ = infer_relation(n1.get("type", ""), n2.get("type", ""))

    return {
        "from": n1["id"],
        "to": n2["id"],
        "from_label": n1.get("label", "")[:40],
        "to_label": n2.get("label", "")[:40],
        "from_type": n1.get("type", ""),
        "to_type": n2.get("type", ""),
        "from_source": n1.get("source", ""),
        "to_source": n2.get("source", ""),
        "span": span,
        "span_score": round(span_score, 4),
        "semantic_score": round(semantic_score, 4),
        "tag_sim": round(tag_sim, 4),
        "type_compat": round(t_compat, 4),
        "content_sim": round(content_sim, 4),
        "cross_source": cross,
        "distance": round(distance, 4),
        "asymmetry": round(asymmetry, 4),
        "passes_4d": passes_4d,
        "constraint_reason": reason,
        "raw_e_v4_gain": span,
        "suggested_relation": relation,
        "suggested_label": f"{n1.get('label','')[:25]}â†”{n2.get('label','')[:25]}",
        "dci_delta": 0.0,
    }


def rank_candidates(kg: dict, min_span: int = 20, min_semantic: float = 0.05,
                    strict_4d: bool = True) -> list:
    """
    v3 í›„ë³´ ë­í‚¹.
    - strict_4d=True: 4D ì œì•½ ìœ„ë°˜ ì‹œ ì œì™¸ (ê¸°ë³¸)
    - strict_4d=False: ì†Œí”„íŠ¸ ëª¨ë“œ â€” ìœ„ë°˜ ì‹œ combinedì—ì„œ 0.10 íŒ¨ë„í‹°

    combined_v3 = base_combined + CROSS_SOURCE_BONUS (êµì°¨ì¶œì²˜ ì‹œ)
    base_combined = 0.35*span_score + 0.35*semantic_score + 0.30*e_v4_gain_norm
    """
    nodes = [n for n in kg["nodes"] if n["id"].startswith("n-")]
    max_node_id = max(node_num(n["id"]) for n in nodes)

    existing = set()
    for e in kg["edges"]:
        existing.add((e["from"], e["to"]))
        existing.add((e["to"], e["from"]))

    candidates = []
    stats = {"filtered_4d": 0, "filtered_sem": 0, "cross": 0, "same": 0}

    for n1, n2 in combinations(nodes, 2):
        if (n1["id"], n2["id"]) in existing:
            continue
        span = abs(node_num(n1["id"]) - node_num(n2["id"]))
        if span < min_span:
            continue

        scored = score_pair(n1, n2, max_node_id)

        if scored["semantic_score"] < min_semantic:
            stats["filtered_sem"] += 1
            continue

        # DCI feeding ê´€ê³„ í•„í„° (v2 ì •ì±… ìœ ì§€)
        if scored["suggested_relation"] in DCI_FEEDING_RELATIONS:
            continue

        # 4D ì œì•½
        if strict_4d and not scored["passes_4d"]:
            stats["filtered_4d"] += 1
            continue

        if scored["cross_source"]:
            stats["cross"] += 1
        else:
            stats["same"] += 1

        candidates.append(scored)

    # í†µê³„ ì¶œë ¥
    total_filtered = stats["filtered_4d"] + stats["filtered_sem"]
    if total_filtered > 0:
        print(f"  ğŸ”¢ 4D í•„í„°: {stats['filtered_4d']}ê°œ ì œì™¸ (distance/asymmetry ë²”ìœ„ ì™¸)")
    print(f"  ğŸ“Š í›„ë³´ í’€ â€” êµì°¨ì¶œì²˜: {stats['cross']}ê°œ / ë™ì¼ì¶œì²˜: {stats['same']}ê°œ")

    if not candidates:
        return candidates

    # E_v4 gain ì •ê·œí™”
    gains = [c["raw_e_v4_gain"] for c in candidates]
    gain_min, gain_max = min(gains), max(gains)
    gain_range = gain_max - gain_min if gain_max != gain_min else 1.0

    for c in candidates:
        e_v4_norm = (c["raw_e_v4_gain"] - gain_min) / gain_range
        c["e_v4_gain_norm"] = round(e_v4_norm, 4)

        # v3 combined: base + cross_source_bonus (êµì°¨ì¶œì²˜ì´ë©´ +0.30 ì§ì ‘ í•©ì‚°)
        base = (
            0.35 * c["span_score"]
            + 0.35 * c["semantic_score"]
            + 0.30 * c["e_v4_gain_norm"]
        )
        cross_add = CROSS_SOURCE_BONUS if c["cross_source"] else 0.0

        # ì†Œí”„íŠ¸ ëª¨ë“œ: 4D ì œì•½ ìœ„ë°˜ ì‹œ íŒ¨ë„í‹°
        penalty = -0.10 if (not strict_4d and not c["passes_4d"]) else 0.0

        c["combined"] = round(base + cross_add + penalty, 4)

    candidates.sort(key=lambda x: -x["combined"])
    return candidates


# â”€â”€â”€ CSER ì œì•½ ê¸°ë°˜ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def select_with_cser_constraint(kg: dict, candidates: list, n: int) -> list:
    """
    CSER >= CSER_MIN ì œì•½ì„ ìœ ì§€í•˜ë©´ì„œ ìƒìœ„ nê°œ ì„ íƒ.

    ê·œì¹™:
    - êµì°¨ì¶œì²˜ ì—£ì§€: í•­ìƒ í—ˆìš© (CSER ìƒìŠ¹ì— ê¸°ì—¬)
    - ë™ì¼ì¶œì²˜ ì—£ì§€: ì¶”ê°€ í›„ CSER >= CSER_MIN ìœ ì§€ë  ë•Œë§Œ í—ˆìš©
    ì´ë¯¸ CSER < CSER_MINì¸ ê²½ìš°: ë™ì¼ì¶œì²˜ ì—£ì§€ ì „ë©´ ì°¨ë‹¨
    (êµì°¨ì¶œì²˜ë§Œ ìŒ“ì•„ì„œ ì„ê³„ê°’ íšŒë³µ)
    """
    node_src = {nd["id"]: nd.get("source", "") for nd in kg["nodes"]}
    cross_now, total_now = compute_cser_raw(kg)
    current_cser = cross_now / total_now if total_now > 0 else 0.0

    selected = []
    skipped_cser = 0

    for c in candidates:
        if len(selected) >= n:
            break

        is_cross = node_src.get(c["from"], "") != node_src.get(c["to"], "")

        if is_cross:
            # êµì°¨ì¶œì²˜: ë¬´ì¡°ê±´ í—ˆìš© (CSER ê°œì„ )
            selected.append(c)
        else:
            # ë™ì¼ì¶œì²˜: í˜„ì¬ CSER < ì„ê³„ê°’ì´ë©´ ì°¨ë‹¨
            if current_cser < CSER_MIN:
                skipped_cser += 1
                continue
            # í˜„ì¬ OK â†’ ì¶”ê°€ í›„ì—ë„ OKì¸ì§€ ì‹œë®¬ë ˆì´ì…˜
            sel_cross = sum(1 for s in selected
                            if node_src.get(s["from"], "") != node_src.get(s["to"], ""))
            projected_cross = cross_now + sel_cross
            projected_total = total_now + len(selected) + 1
            projected_cser = projected_cross / projected_total if projected_total > 0 else 0.0
            if projected_cser < CSER_MIN:
                skipped_cser += 1
                continue
            selected.append(c)

    if skipped_cser > 0:
        print(f"  ğŸ›¡ï¸  CSER ì œì•½: {skipped_cser}ê°œ ë™ì¼ì¶œì²˜ ì—£ì§€ ì œì™¸ (í˜„ì¬ CSER {current_cser:.4f} < {CSER_MIN})")

    return selected


# â”€â”€â”€ E_v4 ì¸¡ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compute_e_v4_delta(kg: dict, additions: list) -> dict:
    sys.path.insert(0, str(REPO))
    from src.metrics import compute_all_metrics

    before = compute_all_metrics(kg)
    test_kg = {"nodes": kg["nodes"], "edges": kg["edges"] + additions}
    after = compute_all_metrics(test_kg)

    e_v4_delta = round(after["E_v4"] - before["E_v4"], 4)
    dci_delta = round(after["DCI"] - before["DCI"], 4)
    cser_delta = round(after["CSER"] - before["CSER"], 4)
    e_v4_gain_excl_dci = round(e_v4_delta - 0.25 * dci_delta, 4)

    return {
        "e_v4_before": before["E_v4"],
        "e_v4_after": after["E_v4"],
        "delta": e_v4_delta,
        "e_v4_gain_excl_dci": e_v4_gain_excl_dci,
        "dci_before": before["DCI"],
        "dci_after": after["DCI"],
        "dci_delta": dci_delta,
        "cser_before": before["CSER"],
        "cser_after": after["CSER"],
        "cser_delta": cser_delta,
        "cser_ok": after["CSER"] >= CSER_MIN,
        "edge_span_before": before["edge_span"]["raw"],
        "edge_span_after": after["edge_span"]["raw"],
        "n_added": len(additions),
    }


# â”€â”€â”€ KGì— ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def add_edges_to_kg(kg: dict, selected: list) -> tuple:
    current_max_edge = max(
        (int(e["id"].replace("e-", "")) for e in kg["edges"] if e["id"].startswith("e-")),
        default=0
    )
    new_edges = []
    for i, c in enumerate(selected, start=1):
        eid = f"e-{current_max_edge + i}"
        edge = {
            "id": eid,
            "from": c["from"],
            "to": c["to"],
            "relation": c["suggested_relation"],
            "label": c["suggested_label"],
            "meta": {
                "source": "pair_designer_v3",
                "version": VERSION,
                "cycle": CYCLE,
                "date": str(date.today()),
                "combined_score": c["combined"],
                "span": c["span"],
                "semantic_score": c["semantic_score"],
                "cross_source": c["cross_source"],
                "cross_source_bonus": CROSS_SOURCE_BONUS if c["cross_source"] else 0.0,
                "distance": c["distance"],
                "asymmetry": c["asymmetry"],
                "passes_4d": c["passes_4d"],
                "dci_neutral": True,
            },
        }
        new_edges.append(edge)

    updated_kg = {"nodes": kg["nodes"], "edges": kg["edges"] + new_edges}
    delta = compute_e_v4_delta(kg, new_edges)
    return updated_kg, new_edges, delta


# â”€â”€â”€ êµì°¨ì¶œì²˜ í†µê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_source_stats(kg: dict) -> None:
    node_src = {n["id"]: n.get("source", "") for n in kg["nodes"]}
    team = {n["id"]: classify_source(n.get("source", "")) for n in kg["nodes"]}

    loki_nodes = sum(1 for t in team.values() if t == "ë¡ì´")
    cokac_nodes = sum(1 for t in team.values() if t == "cokac")
    other_nodes = sum(1 for t in team.values() if t == "ê¸°íƒ€")

    cross_edges = sum(
        1 for e in kg["edges"]
        if node_src.get(e["from"], "") != node_src.get(e["to"], "")
    )
    v3_edges = [e for e in kg["edges"] if e.get("meta", {}).get("source") == "pair_designer_v3"]
    v3_cross = sum(1 for e in v3_edges if e.get("meta", {}).get("cross_source", False))

    sys.path.insert(0, str(REPO))
    from src.metrics import compute_all_metrics
    m = compute_all_metrics(kg)

    print("â•â•â• êµì°¨ì¶œì²˜ í†µê³„ (pair_designer v3) â•â•â•")
    print(f"ë…¸ë“œ â€” ë¡ì´: {loki_nodes}  cokac: {cokac_nodes}  ê¸°íƒ€: {other_nodes}")
    print(f"ì „ì²´ êµì°¨ì¶œì²˜ ì—£ì§€: {cross_edges}/{len(kg['edges'])}  = CSER {m['CSER']:.4f}")
    print(f"v3 ì¶”ê°€ ì—£ì§€: {len(v3_edges)}ê°œ  (êµì°¨ì¶œì²˜: {v3_cross}ê°œ)")
    print(f"CSER >= {CSER_MIN}: {'âœ…' if m['CSER'] >= CSER_MIN else 'âŒ'} (í˜„ì¬ {m['CSER']:.4f})")


# â”€â”€â”€ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_recommendations(candidates: list, top_n: int = 20) -> None:
    cross_in_top = sum(1 for c in candidates[:top_n] if c["cross_source"])
    print("â•â•â• pair_designer v3 â€” CSER ì œì•½ + êµì°¨ì¶œì²˜ ë³´ë„ˆìŠ¤ (ì‚¬ì´í´ 60) â•â•â•")
    print(f"í›„ë³´ í’€: {len(candidates)}ìŒ  |  ìƒìœ„ {min(top_n, len(candidates))}ê°œ í‘œì‹œ")
    print(f"ê°€ì¤‘ì¹˜: span=0.35  semantic=0.35  E_v4=0.30  + cross_bonus={CROSS_SOURCE_BONUS} (êµì°¨ì¶œì²˜)")
    print(f"4D ì œì•½: distanceâˆˆ({DISTANCE_MIN},{DISTANCE_MAX})  asymmetryâˆˆ({ASYMMETRY_MIN},{ASYMMETRY_MAX})")
    print(f"CSER ì œì•½: >= {CSER_MIN}")
    print(f"ìƒìœ„ {min(top_n, len(candidates))}ê°œ ì¤‘ êµì°¨ì¶œì²˜: {cross_in_top}ê°œ")
    print()

    for i, c in enumerate(candidates[:top_n], 1):
        cross_tag = " [êµì°¨âœ“]" if c["cross_source"] else ""
        bonus_tag = f" +{CROSS_SOURCE_BONUS}" if c["cross_source"] else ""
        print(f"  [{i:>2}] {c['from']}â†”{c['to']}  combined={c['combined']:.4f}{bonus_tag}{cross_tag}")
        print(f"       {c['from_type']:<12} â†” {c['to_type']:<12}  span={c['span']}")
        print(f"       dist={c['distance']:.3f}  asym={c['asymmetry']:.2f}"
              f"  sem={c['semantic_score']:.3f}  ({c['from_source']}â†”{c['to_source']})")
        print(f"       \"{c['from_label']}\"")
        print(f"       â†’ [{c['suggested_relation']}]")
        print(f"       \"{c['to_label']}\"")
        print()

    if len(candidates) == 0:
        print("  ì¶”ì²œ ì—†ìŒ â€” --soft í”Œë˜ê·¸ë¡œ ì†Œí”„íŠ¸ ëª¨ë“œ ì‹œë„")


def print_delta_report(delta: dict) -> None:
    arrow = "â†‘" if delta["delta"] >= 0 else "â†“"
    sign = "+" if delta["delta"] >= 0 else ""

    print(f"\nâ”€â”€ E_v4 ì‹¤ì¸¡ ê²°ê³¼ (v3 CSER ì œì•½) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  ì¶”ê°€ëœ ì—£ì§€        : {delta['n_added']}ê°œ")
    print(f"  E_v4               : {delta['e_v4_before']:.4f} â†’ {delta['e_v4_after']:.4f}  ({sign}{delta['delta']:.4f} {arrow})")
    print(f"  e_v4_gain_excl_dci : {'+' if delta['e_v4_gain_excl_dci'] >= 0 else ''}{delta['e_v4_gain_excl_dci']:.4f}")
    print(f"  DCI ë³€í™”           : {delta['dci_before']:.4f} â†’ {delta['dci_after']:.4f}  (Î”{delta['dci_delta']:+.4f})")
    print(f"  CSER               : {delta['cser_before']:.4f} â†’ {delta['cser_after']:.4f}  (Î”{delta['cser_delta']:+.4f})")
    cser_status = "âœ… ì œì•½ ì¤€ìˆ˜" if delta["cser_ok"] else f"âŒ ì œì•½ ìœ„ë°˜ ({CSER_MIN} ë¯¸ë‹¬)"
    print(f"  CSER >= {CSER_MIN}        : {cser_status}")
    print(f"  edge_span_raw      : {delta['edge_span_before']:.3f} â†’ {delta['edge_span_after']:.3f}")

    if delta["dci_delta"] > 0.005:
        print(f"\n  âš ï¸  DCI ì¦ê°€ ê°ì§€: Î”{delta['dci_delta']:+.4f}")
    else:
        print(f"\n  âœ… DCI ì¤‘ë¦½: Î”{delta['dci_delta']:+.4f}")

    if delta["cser_delta"] >= 0:
        print(f"  âœ… CSER ìœ ì§€/ìƒìŠ¹: Î”{delta['cser_delta']:+.4f}")
    else:
        print(f"  âš ï¸  CSER ì†Œí­ í•˜ë½: Î”{delta['cser_delta']:+.4f} â€” CSER {'OK' if delta['cser_ok'] else 'ì œì•½ ìœ„ë°˜'}")


# â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    args = sys.argv[1:]
    kg = load_kg()

    top_n = 20
    min_span = 20
    add_n = 0
    strict_4d = "--soft" not in args

    for i, arg in enumerate(args):
        if arg == "--top" and i + 1 < len(args):
            try:
                top_n = int(args[i + 1])
            except ValueError:
                pass
        if arg == "--add" and i + 1 < len(args):
            try:
                add_n = int(args[i + 1])
            except ValueError:
                add_n = top_n
        if arg == "--min-span" and i + 1 < len(args):
            try:
                min_span = int(args[i + 1])
            except ValueError:
                pass

    if "--source-stats" in args:
        cmd_source_stats(kg)
        return

    if "--verify" in args:
        log = load_log()
        if not log["sessions"]:
            print("ê¸°ë¡ ì—†ìŒ")
            return
        last = log["sessions"][-1]
        print(json.dumps(last, ensure_ascii=False, indent=2))
        return

    mode_label = "ì†Œí”„íŠ¸(4D í˜ë„í‹°)" if not strict_4d else "ì—„ê²©(4D í•˜ë“œí•„í„°)"
    print(f"  ğŸ”§ ëª¨ë“œ: {mode_label}")

    candidates = rank_candidates(kg, min_span=min_span, min_semantic=0.05, strict_4d=strict_4d)

    if "--json" in args:
        output = {
            "version": VERSION,
            "candidates": candidates[:top_n],
            "total_pool": len(candidates),
            "params": {
                "top_n": top_n,
                "min_span": min_span,
                "strict_4d": strict_4d,
                "cross_source_bonus": CROSS_SOURCE_BONUS,
                "cser_min": CSER_MIN,
            },
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
        return

    if add_n > 0:
        n = min(add_n, len(candidates))
        if n == 0:
            print("ì¶”ì²œ í›„ë³´ ì—†ìŒ â€” --soft ëª¨ë“œ ë˜ëŠ” íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”")
            return

        print(f"â•â•â• pair_designer v3 --add {n} (CSER ì œì•½ + êµì°¨ì¶œì²˜) â•â•â•\n")

        # CSER ì œì•½ ê¸°ë°˜ ì„ íƒ
        selected = select_with_cser_constraint(kg, candidates, n)
        actual_n = len(selected)

        if actual_n == 0:
            print("CSER ì œì•½ìœ¼ë¡œ ì„ íƒ ê°€ëŠ¥í•œ ì—£ì§€ ì—†ìŒ")
            return

        cross_selected = sum(1 for s in selected if s["cross_source"])
        print(f"\n  ì„ íƒëœ ì—£ì§€ {actual_n}ê°œ â€” êµì°¨ì¶œì²˜: {cross_selected}ê°œ / ë™ì¼ì¶œì²˜: {actual_n - cross_selected}ê°œ")

        updated_kg, added, delta = add_edges_to_kg(kg, selected)
        save_kg(updated_kg)
        print_delta_report(delta)

        log = load_log()
        session = {
            "date": str(date.today()),
            "version": VERSION,
            "cycle": CYCLE,
            "n_added": actual_n,
            "cross_source_count": cross_selected,
            "delta": delta,
            "added_edges": [
                {
                    "id": e["id"],
                    "from": e["from"],
                    "to": e["to"],
                    "relation": e["relation"],
                    "span": e["meta"]["span"],
                    "combined_score": e["meta"]["combined_score"],
                    "cross_source": e["meta"]["cross_source"],
                    "distance": e["meta"]["distance"],
                    "asymmetry": e["meta"]["asymmetry"],
                }
                for e in added
            ],
        }
        log["sessions"].append(session)
        save_log(log)
        print(f"\n  âœ… {actual_n}ê°œ ì—£ì§€ ì¶”ê°€ ì™„ë£Œ â†’ data/knowledge-graph.json")
        print(f"  ë¡œê·¸ â†’ data/pair_designer_v3_log.json")
        return

    print_recommendations(candidates, top_n)


if __name__ == "__main__":
    main()
