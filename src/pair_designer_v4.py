#!/usr/bin/env python3
"""
pair_designer_v4.py â€” KG ìê°€ ìµœì í™” ì—”ì§„ v4 (CSER ì œì•½ ì œê±° + edge_span ì§ì ‘ ìµœì í™”)

v3 ì—­ì„¤ (D-065):
  pair_designer_v3ì˜ CSER ìµœì í™”ê°€ E_v4 > E_v3 ì—­ì „ì„ ë°©í•´í•¨.
  E_v3 CSER ê°€ì¤‘ì¹˜(0.40) > E_v4 CSER ê°€ì¤‘ì¹˜(0.35) â†’ CSER ìƒìŠ¹ ì‹œ E_v3ê°€ ë” ë¹ ë¥´ê²Œ ì¦ê°€.
  ê²°ê³¼: Î”(E_v4 - E_v3) í™•ëŒ€ ë¶ˆê°€.

v4 ì „ëµ (D-067, D-068):
  CSER ì œì•½ ì™„ì „ ì œê±°.
  edge_span_norm + node_age_diversityë¥¼ ì§ì ‘ ìµœì í™”.
  E_v4 ì¦ê°€ì— ì§ì ‘ ê¸°ì—¬í•˜ëŠ” ì§€í‘œë¥¼ ì„ íƒ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©.

combined_v4 = 0.50Ã—edge_span_norm + 0.30Ã—node_age_diversity + 0.20Ã—cross_bonus

  - edge_span_norm (0.50): E_v4ì—ì„œ Î³=0.25 â€” ê°€ì¥ ì§ì ‘ì  ê¸°ì—¬ ê²½ë¡œ
  - node_age_diversity (0.30): E_v4ì—ì„œ Î´=0.15 ê¸°ì—¬
  - cross_bonus (0.20): êµì°¨ì¶œì²˜ ìŒì— ë³´ë„ˆìŠ¤ (D-033 ì›ì¹™ ìœ ì§€)
  * CSER ì œì•½ ì—†ìŒ: CSERëŠ” E_v4 ì¦ê°€ë¥¼ ë°©í•´í•˜ëŠ” v3 ì—­ì„¤ì—ì„œ íƒˆì¶œ

ì‚¬ìš©ë²•:
  python3 src/pair_designer_v4.py              # ìƒìœ„ 20ê°œ ì¶”ì²œ
  python3 src/pair_designer_v4.py --top 15     # ìƒìœ„ 15ê°œ
  python3 src/pair_designer_v4.py --json       # JSON ì¶œë ¥
  python3 src/pair_designer_v4.py --add N      # KGì— Nê°œ ì¶”ê°€ + Î”(E_v4 - E_v3) ì¸¡ì •
  python3 src/pair_designer_v4.py --verify     # ë§ˆì§€ë§‰ ì¶”ê°€ ê²°ê³¼ ì¶œë ¥
  python3 src/pair_designer_v4.py --compare    # v3 vs v4 ì„ íƒ ë¹„êµ

êµ¬í˜„: ë¡ì´ (ëƒ‰ì •í•œ íŒì‚¬) â€” ì‚¬ì´í´ 78, D-070
"""

import json
import re
import sys
import statistics
from pathlib import Path
from datetime import date
from itertools import combinations

REPO = Path(__file__).parent.parent
KG_FILE     = REPO / "data" / "knowledge-graph.json"
RESULT_FILE = REPO / "data" / "pair_designer_v4_log.json"

VERSION = "v4"
CYCLE   = 78

# â”€â”€â”€ v4 í•µì‹¬ ìƒìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# combined_v4 ê°€ì¤‘ì¹˜
W_EDGE_SPAN  = 0.50   # edge_span_norm ê¸°ì—¬ (E_v4 Î³=0.25 ì§ì ‘ ìµœì í™”)
W_NODE_AGE   = 0.30   # node_age_diversity ê¸°ì—¬ (E_v4 Î´=0.15 ì§ì ‘ ìµœì í™”)
W_CROSS      = 0.20   # êµì°¨ì¶œì²˜ ë³´ë„ˆìŠ¤ (D-033 ì›ì¹™)

# v3ì™€ ë‹¬ë¦¬ CSER ì œì•½ ì—†ìŒ
# CSER_MIN ì •ì˜ ì—†ìŒ â€” v3 ì—­ì„¤ íƒˆì¶œ

# ìµœì†Œ span (ì—£ì§€ ê¸¸ì´ í•˜í•œ)
MIN_SPAN = 20

# DCI feeding ê´€ê³„ í•„í„°
DCI_FEEDING_RELATIONS = {"answers", "addresses"}

# ì¶œì²˜ ë¶„ë¥˜
LOKI_SOURCES  = {"ë¡ì´", "ìƒë¡"}
COKAC_SOURCES = {"cokac", "cokac-bot"}

# â”€â”€â”€ íƒ€ì… í˜¸í™˜ì„± í–‰ë ¬ (v3 ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TYPE_COMPAT = {
    ("insight",     "question"):    0.85,
    ("observation", "question"):    0.80,
    ("prediction",  "question"):    0.75,
    ("prediction",  "observation"): 0.90,
    ("prediction",  "insight"):     0.70,
    ("insight",     "insight"):     0.60,
    ("insight",     "observation"): 0.65,
    ("insight",     "decision"):    0.72,
    ("decision",    "observation"): 0.65,
    ("decision",    "question"):    0.68,
    ("observation", "observation"): 0.45,
    ("insight",     "experiment"):  0.75,
    ("observation", "experiment"):  0.80,
    ("prediction",  "experiment"):  0.85,
    ("question",    "experiment"):  0.70,
    ("concept",     "insight"):     0.65,
    ("concept",     "observation"): 0.60,
    ("concept",     "question"):    0.65,
    ("finding",     "insight"):     0.75,
    ("finding",     "prediction"):  0.70,
    ("finding",     "observation"): 0.72,
    ("synthesis",   "insight"):     0.80,
    ("synthesis",   "observation"): 0.75,
    ("artifact",    "insight"):     0.55,
    ("artifact",    "experiment"):  0.65,
    ("tool",        "experiment"):  0.70,
    ("tool",        "artifact"):    0.60,
    ("persona",     "observation"): 0.55,
    ("persona",     "insight"):     0.50,
}
DEFAULT_COMPAT = 0.30

RELATION_HINT = {
    ("insight",     "question"):    ("resonates_with", "ì¸ì‚¬ì´íŠ¸ê°€ ì§ˆë¬¸ê³¼ ê³µëª…í•œë‹¤"),
    ("observation", "question"):    ("contextualizes", "ê´€ì°°ì´ ì§ˆë¬¸ì˜ ë§¥ë½ì„ ì œê³µí•œë‹¤"),
    ("prediction",  "question"):    ("parallel_to",    "ì˜ˆì¸¡ì´ ì§ˆë¬¸ê³¼ ë³‘ë ¬ë¡œ ì „ê°œëœë‹¤"),
    ("prediction",  "observation"): ("validated_by",   "ê´€ì°°ì´ ì˜ˆì¸¡ì„ ê²€ì¦í•œë‹¤"),
    ("prediction",  "insight"):     ("informed_by",    "ì˜ˆì¸¡ì´ ì¸ì‚¬ì´íŠ¸ì— ê·¼ê±°í•œë‹¤"),
    ("insight",     "insight"):     ("extends",        "ì¸ì‚¬ì´íŠ¸ê°€ ë‹¤ë¥¸ ì¸ì‚¬ì´íŠ¸ë¥¼ í™•ì¥í•œë‹¤"),
    ("insight",     "observation"): ("grounds",        "ì¸ì‚¬ì´íŠ¸ê°€ ê´€ì°°ì— ê·¼ê±°í•œë‹¤"),
    ("insight",     "decision"):    ("supports",       "ì¸ì‚¬ì´íŠ¸ê°€ ê²°ì •ì„ ì§€ì§€í•œë‹¤"),
    ("observation", "experiment"):  ("evidence_for",   "ê´€ì°°ì´ ì‹¤í—˜ ì¦ê±°ê°€ ëœë‹¤"),
    ("prediction",  "experiment"):  ("tested_by",      "ì˜ˆì¸¡ì´ ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦ëœë‹¤"),
    ("finding",     "insight"):     ("generalizes",    "ë°œê²¬ì´ ì¸ì‚¬ì´íŠ¸ë¡œ ì¼ë°˜í™”ëœë‹¤"),
    ("synthesis",   "insight"):     ("synthesizes",    "í•©ì„±ì´ ì¸ì‚¬ì´íŠ¸ë¥¼ í†µí•©í•œë‹¤"),
    ("concept",     "insight"):     ("resonates_with", "ê°œë…ì´ ì¸ì‚¬ì´íŠ¸ì™€ ê³µëª…í•œë‹¤"),
    ("concept",     "question"):    ("parallel_to",    "ê°œë…ì´ ì§ˆë¬¸ê³¼ ë³‘ë ¬ë¡œ íƒêµ¬ëœë‹¤"),
    ("finding",     "prediction"):  ("extends",        "ë°œê²¬ì´ ì˜ˆì¸¡ì„ í™•ì¥í•œë‹¤"),
    ("synthesis",   "observation"): ("grounds",        "í•©ì„±ì´ ê´€ì°°ì— ê·¼ê±°í•œë‹¤"),
}
DEFAULT_RELATION = ("relates_to", "ì˜ë¯¸ë¡ ì  ì—°ê²°")


# â”€â”€â”€ I/O â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_kg() -> dict:
    return json.loads(KG_FILE.read_text(encoding="utf-8"))


def save_kg(kg: dict) -> None:
    existing_nums = [
        int(n["id"].split("-")[1]) for n in kg["nodes"]
        if n["id"].startswith("n-") and n["id"].split("-")[1].isdigit()
    ]
    if "meta" not in kg:
        next_num = (max(existing_nums) + 1) if existing_nums else 1
        kg["meta"] = {
            "next_node_id": f"n-{next_num:03d}",
            "last_updated": str(date.today()),
            "total_nodes":  len(kg["nodes"]),
            "total_edges":  len(kg["edges"]),
        }
    else:
        kg["meta"]["total_nodes"]  = len(kg["nodes"])
        kg["meta"]["total_edges"]  = len(kg["edges"])
        kg["meta"]["last_updated"] = str(date.today())
    KG_FILE.write_text(
        json.dumps(kg, ensure_ascii=False, indent=2) + "\n",
        encoding="utf-8",
    )


def load_log() -> dict:
    if RESULT_FILE.exists():
        return json.loads(RESULT_FILE.read_text(encoding="utf-8"))
    return {
        "meta": {
            "description": "pair_designer v4 ì´ë ¥ (CSER ì œì•½ ì œê±° + edge_span ì§ì ‘ ìµœì í™”)",
            "created_cycle": CYCLE,
            "version":       VERSION,
        },
        "sessions": [],
    }


def save_log(data: dict) -> None:
    RESULT_FILE.write_text(
        json.dumps(data, ensure_ascii=False, indent=2) + "\n",
        encoding="utf-8",
    )


# â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def node_num(nid: str) -> int:
    try:
        return int(nid.replace("n-", ""))
    except ValueError:
        return 0


def tokenize(text: str) -> set:
    words = re.split(r"[\s\n\r\t\u3000.,!?;:ã€Œã€ã€ã€ã€ã€‘()ï¼ˆï¼‰\-_/]+", text.lower())
    return {w for w in words if len(w) >= 2 and not w.isdigit()}


def jaccard(a: set, b: set) -> float:
    union = a | b
    return len(a & b) / len(union) if union else 0.0


def type_compat(t1: str, t2: str) -> float:
    return TYPE_COMPAT.get(tuple(sorted([t1, t2])), DEFAULT_COMPAT)


def infer_relation(t1: str, t2: str) -> tuple:
    key = tuple(sorted([t1, t2]))
    rel, lbl = RELATION_HINT.get(key, DEFAULT_RELATION)
    if rel in DCI_FEEDING_RELATIONS:
        return ("resonates_with", f"{t1}â†”{t2} ê³µëª…")
    return rel, lbl


def classify_source(src: str) -> str:
    if src in LOKI_SOURCES:  return "ë¡ì´"
    if src in COKAC_SOURCES: return "cokac"
    return "ê¸°íƒ€"


def is_cross_source(n1: dict, n2: dict) -> bool:
    t1 = classify_source(n1.get("source", ""))
    t2 = classify_source(n2.get("source", ""))
    return t1 != t2 and "ê¸°íƒ€" not in (t1, t2)


# â”€â”€â”€ v4 í•µì‹¬: edge_span_norm + node_age_diversity ì§ì ‘ ì ìˆ˜í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def score_pair_v4(n1: dict, n2: dict, max_node_id: int, kg_stdev: float, kg_mean: float) -> dict:
    """
    v4 ì ìˆ˜ ê³„ì‚°.
    combined_v4 = W_EDGE_SPANÃ—edge_span_norm + W_NODE_AGEÃ—age_contribution + W_CROSSÃ—cross_flag

    edge_span_norm: ì´ ì—£ì§€ì˜ span / max_node_id
    age_contribution: ë‘ ë…¸ë“œ IDì˜ ì°¨ì´ê°€ ì „ì²´ node_age_diversityì— ê¸°ì—¬í•˜ëŠ” ì •ë„ (proxy)
    cross_flag: êµì°¨ì¶œì²˜ì´ë©´ 1.0, ì•„ë‹ˆë©´ 0.0
    """
    id1  = node_num(n1["id"])
    id2  = node_num(n2["id"])
    span = abs(id1 - id2)

    edge_span_norm = span / max_node_id if max_node_id > 0 else 0.0

    # node_age_diversity contribution proxy:
    # ë‘ ë…¸ë“œ IDê°€ í‰ê· ì—ì„œ ì–¼ë§ˆë‚˜ ë©€ë¦¬ í¼ì ¸ ìˆëŠ”ì§€ (std ê¸°ì—¬ ì¶”ì •)
    # ì •í™•í•œ std ë³€í™” ê³„ì‚°ì€ ì „ì²´ ë…¸ë“œ ì¬ê³„ì‚°ì´ í•„ìš” â€” span_normì„ ëŒ€ë¦¬ ì§€í‘œë¡œ ì‚¬ìš©
    age_contrib = edge_span_norm  # spanì´ í´ìˆ˜ë¡ age diversityì— ê¸°ì—¬

    cross = is_cross_source(n1, n2)
    cross_flag = 1.0 if cross else 0.0

    combined = round(
        W_EDGE_SPAN * edge_span_norm
        + W_NODE_AGE * age_contrib
        + W_CROSS    * cross_flag,
        4,
    )

    # ê´€ê³„ ì¶”ë¡  (DCI feeding í•„í„°ìš©)
    relation, _ = infer_relation(n1.get("type", ""), n2.get("type", ""))

    # ì˜ë¯¸ë¡ ì  ì ìˆ˜ (í•„í„°ìš© â€” v3 ë°©ì‹ ìœ ì§€)
    tags1    = set(n1.get("tags", []))
    tags2    = set(n2.get("tags", []))
    tag_sim  = jaccard(tags1, tags2)
    t_compat = type_compat(n1.get("type", ""), n2.get("type", ""))
    c1       = tokenize(n1.get("content", "") + " " + n1.get("label", ""))
    c2       = tokenize(n2.get("content", "") + " " + n2.get("label", ""))
    cont_sim = jaccard(c1, c2)
    semantic = round(0.40 * tag_sim + 0.35 * t_compat + 0.25 * cont_sim, 4)

    return {
        "from":               n1["id"],
        "to":                 n2["id"],
        "from_label":         n1.get("label", "")[:40],
        "to_label":           n2.get("label", "")[:40],
        "from_type":          n1.get("type", ""),
        "to_type":            n2.get("type", ""),
        "from_source":        n1.get("source", ""),
        "to_source":          n2.get("source", ""),
        "span":               span,
        "edge_span_norm":     round(edge_span_norm, 4),
        "age_contrib":        round(age_contrib, 4),
        "cross_source":       cross,
        "cross_flag":         cross_flag,
        "semantic_score":     semantic,
        "combined":           combined,
        "suggested_relation": relation,
        "suggested_label":    f"{n1.get('label','')[:25]}â†”{n2.get('label','')[:25]}",
    }


def rank_candidates(kg: dict) -> list:
    """
    v4 í›„ë³´ ë­í‚¹.
    CSER ì œì•½ ì—†ìŒ. DCI feeding ê´€ê³„ë§Œ í•„í„°.
    min_semantic ì—†ìŒ (edge_spanì´ ê¸°ì¤€).
    """
    nodes      = [n for n in kg["nodes"] if n["id"].startswith("n-")]
    max_nid    = max(node_num(n["id"]) for n in nodes)
    nids       = [node_num(n["id"]) for n in nodes]
    kg_stdev   = statistics.stdev(nids) if len(nids) > 1 else 1.0
    kg_mean    = statistics.mean(nids)

    existing = set()
    for e in kg["edges"]:
        existing.add((e["from"], e["to"]))
        existing.add((e["to"],   e["from"]))

    candidates = []
    stats = {"cross": 0, "same": 0, "filtered_dci": 0}

    for n1, n2 in combinations(nodes, 2):
        if (n1["id"], n2["id"]) in existing:
            continue
        span = abs(node_num(n1["id"]) - node_num(n2["id"]))
        if span < MIN_SPAN:
            continue

        scored = score_pair_v4(n1, n2, max_nid, kg_stdev, kg_mean)

        # DCI feeding í•„í„°
        if scored["suggested_relation"] in DCI_FEEDING_RELATIONS:
            stats["filtered_dci"] += 1
            continue

        if scored["cross_source"]:
            stats["cross"] += 1
        else:
            stats["same"] += 1

        candidates.append(scored)

    print(f"  ğŸ“Š í›„ë³´ í’€ â€” êµì°¨ì¶œì²˜: {stats['cross']}ê°œ / ë™ì¼ì¶œì²˜: {stats['same']}ê°œ"
          f"  (DCI í•„í„°: {stats['filtered_dci']}ê°œ ì œì™¸)")

    candidates.sort(key=lambda x: -x["combined"])
    return candidates


# â”€â”€â”€ E_v4 / E_v3 delta ì¸¡ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compute_delta(kg: dict, additions: list) -> dict:
    sys.path.insert(0, str(REPO))
    from src.metrics import compute_all_metrics

    before = compute_all_metrics(kg)
    test_kg = {"nodes": kg["nodes"], "edges": kg["edges"] + additions}
    after  = compute_all_metrics(test_kg)

    ev4_before = before["E_v4"]
    ev3_before = before["E_v3"]
    ev4_after  = after["E_v4"]
    ev3_after  = after["E_v3"]

    return {
        "E_v4_before":  ev4_before,
        "E_v4_after":   ev4_after,
        "E_v4_delta":   round(ev4_after - ev4_before, 4),
        "E_v3_before":  ev3_before,
        "E_v3_after":   ev3_after,
        "E_v3_delta":   round(ev3_after - ev3_before, 4),
        "gap_before":   round(ev4_before - ev3_before, 4),
        "gap_after":    round(ev4_after  - ev3_after,  4),
        "gap_delta":    round((ev4_after - ev3_after) - (ev4_before - ev3_before), 4),
        "CSER_before":  before["CSER"],
        "CSER_after":   after["CSER"],
        "DCI_before":   before["DCI"],
        "DCI_after":    after["DCI"],
        "edge_span_before": before["edge_span"]["raw"],
        "edge_span_after":  after["edge_span"]["raw"],
        "n_added":      len(additions),
        "v4_success":   (ev4_after - ev3_after) > 0,
    }


# â”€â”€â”€ KGì— ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def add_edges_to_kg(kg: dict, selected: list) -> tuple:
    max_eid = max(
        (int(e["id"].replace("e-", ""))
         for e in kg["edges"]
         if e.get("id", "").startswith("e-") and e["id"].replace("e-", "").isdigit()),
        default=0,
    )
    new_edges = []
    for i, c in enumerate(selected, start=1):
        new_edges.append({
            "id":       f"e-{max_eid + i}",
            "from":     c["from"],
            "to":       c["to"],
            "relation": c["suggested_relation"],
            "label":    c["suggested_label"],
            "meta": {
                "source":        "pair_designer_v4",
                "version":       VERSION,
                "cycle":         CYCLE,
                "date":          str(date.today()),
                "combined_v4":   c["combined"],
                "span":          c["span"],
                "edge_span_norm": c["edge_span_norm"],
                "cross_source":  c["cross_source"],
                "dci_neutral":   True,
            },
        })

    updated_kg = {"nodes": kg["nodes"], "edges": kg["edges"] + new_edges}
    delta      = compute_delta(kg, new_edges)
    return updated_kg, new_edges, delta


# â”€â”€â”€ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_recommendations(candidates: list, top_n: int) -> None:
    n = min(top_n, len(candidates))
    cross_n = sum(1 for c in candidates[:n] if c["cross_source"])
    print("â•â•â• pair_designer v4 â€” CSER ì œì•½ ì œê±° + edge_span ì§ì ‘ ìµœì í™” (ì‚¬ì´í´ 78) â•â•â•")
    print(f"í›„ë³´: {len(candidates)}ìŒ  |  ìƒìœ„ {n}ê°œ")
    print(f"combined_v4 = {W_EDGE_SPAN}Ã—edge_span_norm + {W_NODE_AGE}Ã—age_contrib + {W_CROSS}Ã—cross_flag")
    print(f"CSER ì œì•½: ì—†ìŒ (v3 ì—­ì„¤ íƒˆì¶œ)")
    print(f"ìƒìœ„ {n}ê°œ ì¤‘ êµì°¨ì¶œì²˜: {cross_n}ê°œ")
    print()

    for i, c in enumerate(candidates[:n], 1):
        cross_tag = " [êµì°¨âœ“]" if c["cross_source"] else ""
        print(f"  [{i:>2}] {c['from']}â†”{c['to']}  combined={c['combined']:.4f}{cross_tag}")
        print(f"       {c['from_type']:<12} â†” {c['to_type']:<12}  span={c['span']}")
        print(f"       edge_span_norm={c['edge_span_norm']:.4f}  semantic={c['semantic_score']:.4f}")
        print(f"       \"{c['from_label']}\"")
        print(f"       â†’ [{c['suggested_relation']}]")
        print(f"       \"{c['to_label']}\"")
        print()

    if not candidates:
        print("  ì¶”ì²œ ì—†ìŒ")


def print_delta_report(delta: dict) -> None:
    print(f"\nâ”€â”€ v4 ì‹¤ì¸¡ ê²°ê³¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  ì¶”ê°€ ì—£ì§€: {delta['n_added']}ê°œ")
    print()
    print(f"  E_v4: {delta['E_v4_before']:.4f} â†’ {delta['E_v4_after']:.4f}  ({delta['E_v4_delta']:+.4f})")
    print(f"  E_v3: {delta['E_v3_before']:.4f} â†’ {delta['E_v3_after']:.4f}  ({delta['E_v3_delta']:+.4f})")
    print()
    gap_sign = "+" if delta["gap_after"] >= 0 else ""
    print(f"  Î”(E_v4 - E_v3) before: {delta['gap_before']:+.4f}")
    print(f"  Î”(E_v4 - E_v3) after:  {gap_sign}{delta['gap_after']:.4f}")
    print(f"  gap ë³€í™”:               {delta['gap_delta']:+.4f}")
    print()
    if delta["v4_success"]:
        print(f"  âœ… ì‹¤í—˜ B ì„±ê³µ: E_v4 > E_v3 (gap={delta['gap_after']:+.4f})")
    else:
        print(f"  âŒ ì‹¤í—˜ B ì‹¤íŒ¨: E_v4 â‰¤ E_v3 (gap={delta['gap_after']:+.4f})")
        print(f"     CSER ì†ì‹¤ì´ edge_span ì´ë“ì„ ìƒì‡„. v3 ì—­ì„¤ êµ¬ì¡° ì§€ì†.")
    print()
    print(f"  CSER: {delta['CSER_before']:.4f} â†’ {delta['CSER_after']:.4f}")
    print(f"  DCI:  {delta['DCI_before']:.4f} â†’ {delta['DCI_after']:.4f}")
    print(f"  edge_span: {delta['edge_span_before']:.3f} â†’ {delta['edge_span_after']:.3f}")


# â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    args = sys.argv[1:]
    kg   = load_kg()

    top_n = 20
    add_n = 0

    for i, arg in enumerate(args):
        if arg == "--top" and i + 1 < len(args):
            try: top_n = int(args[i + 1])
            except ValueError: pass
        if arg == "--add" and i + 1 < len(args):
            try: add_n = int(args[i + 1])
            except ValueError: add_n = top_n

    if "--verify" in args:
        log = load_log()
        if not log["sessions"]:
            print("ê¸°ë¡ ì—†ìŒ")
            return
        print(json.dumps(log["sessions"][-1], ensure_ascii=False, indent=2))
        return

    print(f"  KG: {len(kg['nodes'])} ë…¸ë“œ / {len(kg['edges'])} ì—£ì§€")
    print(f"  ëª¨ë“œ: v4 (CSER ì œì•½ ì—†ìŒ â€” edge_span ì§ì ‘ ìµœì í™”)\n")

    candidates = rank_candidates(kg)

    if "--json" in args:
        print(json.dumps({
            "version":    VERSION,
            "candidates": candidates[:top_n],
            "total_pool": len(candidates),
            "params": {
                "top_n":        top_n,
                "W_EDGE_SPAN":  W_EDGE_SPAN,
                "W_NODE_AGE":   W_NODE_AGE,
                "W_CROSS":      W_CROSS,
            },
        }, ensure_ascii=False, indent=2))
        return

    if add_n > 0:
        n = min(add_n, len(candidates))
        if n == 0:
            print("ì¶”ì²œ í›„ë³´ ì—†ìŒ")
            return

        print(f"â•â•â• pair_designer v4 --add {n} â•â•â•\n")
        selected = candidates[:n]
        cross_n  = sum(1 for s in selected if s["cross_source"])
        print(f"  ì„ íƒ: {n}ê°œ â€” êµì°¨ì¶œì²˜: {cross_n}ê°œ / ë™ì¼ì¶œì²˜: {n - cross_n}ê°œ")

        updated_kg, added, delta = add_edges_to_kg(kg, selected)
        save_kg(updated_kg)
        print_delta_report(delta)

        log = load_log()
        log["sessions"].append({
            "date":         str(date.today()),
            "version":      VERSION,
            "cycle":        CYCLE,
            "n_added":      len(added),
            "cross_count":  cross_n,
            "delta":        delta,
            "added_edges": [
                {
                    "id":             e["id"],
                    "from":           e["from"],
                    "to":             e["to"],
                    "relation":       e["relation"],
                    "span":           e["meta"]["span"],
                    "edge_span_norm": e["meta"]["edge_span_norm"],
                    "combined_v4":    e["meta"]["combined_v4"],
                    "cross_source":   e["meta"]["cross_source"],
                }
                for e in added
            ],
        })
        save_log(log)
        print(f"\n  âœ… {len(added)}ê°œ ì—£ì§€ ì¶”ê°€ â†’ data/knowledge-graph.json")
        print(f"  ë¡œê·¸ â†’ data/pair_designer_v4_log.json")
        return

    print_recommendations(candidates, top_n)


if __name__ == "__main__":
    main()
