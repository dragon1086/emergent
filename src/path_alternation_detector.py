#!/usr/bin/env python3
"""
path_alternation_detector.py â€” ì‚¬ì´í´ 32 êµ¬í˜„
êµ¬í˜„ì: cokac-bot

ì¶œì²˜ êµëŒ€ ê²½ë¡œ(Source Alternation Path)ë¥¼ ìë™ íƒì§€í•œë‹¤.
íƒì§€ ê²°ê³¼ë¡œ ì°½ë°œ ì˜ˆì¸¡ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ ê²€ì¦í•œë‹¤.

n-052 ì‹¤í˜„: path_alternation_detector.py êµ¬ì¶• ê²°ì • â€” D-033Ã—D-034 ìë™ ì™„ì „í™”

í•µì‹¬ ê°€ì„¤ (D-033 Ã— D-034):
  ì¶œì²˜ êµëŒ€ ê²½ë¡œ(ë¡ì´â†’cokacâ†’ë¡ì´â†’...) = ê°­ 27 ë©”ì»¤ë‹ˆì¦˜ì˜ êµ¬ì¡°ì  ì›ì¸
  íƒì§€ â†’ ì˜ˆì¸¡ â†’ ê²€ì¦ì˜ ë£¨í”„ê°€ ë‹«íˆë©´ ì°½ë°œì„ ì˜ˆì–¸í•  ìˆ˜ ìˆë‹¤.

ì‚¬ìš©ë²•:
  python path_alternation_detector.py detect           # êµëŒ€ ê²½ë¡œ ì „ì²´ íƒì§€
  python path_alternation_detector.py detect --min-len 4   # ìµœì†Œ ê¸¸ì´ 4 ì´ìƒ
  python path_alternation_detector.py detect --min-score 0.8  # êµëŒ€ ì ìˆ˜ 0.8 ì´ìƒ
  python path_alternation_detector.py top              # êµëŒ€ ì ìˆ˜ Top 10
  python path_alternation_detector.py predict          # ì°½ë°œ ì˜ˆì¸¡ (ë‹¤ìŒ ê°­ 27 í›„ë³´)
  python path_alternation_detector.py correlate        # ê°­ 27 ë…¸ë“œì™€ ìƒê´€ê´€ê³„
  python path_alternation_detector.py stats            # êµëŒ€ íŒ¨í„´ í†µê³„
  python path_alternation_detector.py save-node        # íƒì§€ ê²°ê³¼ë¥¼ KG ë…¸ë“œë¡œ ì €ì¥
"""

import json
import sys
import argparse
from collections import defaultdict, deque
from itertools import combinations
from pathlib import Path
from datetime import datetime

REPO_DIR = Path(__file__).parent.parent
KG_FILE = REPO_DIR / "data" / "knowledge-graph.json"

# ì¶œì²˜ ì •ê·œí™” â€” cokac-bot, cokac â†’ 'cokac' / ë¡ì´, ìƒë¡ â†’ 'ë¡ì´'
SOURCE_ALIAS = {
    "cokac-bot": "cokac",
    "cokac": "cokac",
    "ë¡ì´": "ë¡ì´",
    "ìƒë¡": "ë¡ì´",
}

# ê°­ 27 ê´€ë ¨ ë…¸ë“œ (n-040~n-050 ë²”ìœ„, ê°­ 27 ê´€ë ¨ ë ˆì´ë¸” í¬í•¨)
GAP27_KEYWORDS = ["ê°­ 27", "gap27", "í° ë„ì•½", "ì§€ì—° ìˆ˜ë ´", "DCI", "ë²•ì¹™í™”"]


# â”€â”€â”€ I/O â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_kg():
    with open(KG_FILE) as f:
        return json.load(f)

def save_kg(kg):
    with open(KG_FILE, "w") as f:
        json.dump(kg, f, ensure_ascii=False, indent=2)

def normalize_source(raw: str) -> str:
    return SOURCE_ALIAS.get(raw, raw)


# â”€â”€â”€ ê·¸ë˜í”„ êµ¬ì¡° êµ¬ì¶• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_graph(kg):
    """ì¸ì ‘ ë¦¬ìŠ¤íŠ¸(ì–‘ë°©í–¥)ì™€ ë…¸ë“œ ì¸ë±ìŠ¤ êµ¬ì¶•"""
    nodes = {n["id"]: n for n in kg["nodes"]}
    adj = defaultdict(list)  # from_id -> [(to_id, edge), ...]
    for e in kg["edges"]:
        adj[e["from"]].append((e["to"], e))
        adj[e["to"]].append((e["from"], e))  # ë¬´ë°©í–¥ íƒìƒ‰
    return nodes, adj


# â”€â”€â”€ êµëŒ€ ì ìˆ˜ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def alternation_score(path_nodes, nodes_index):
    """
    ì¶œì²˜ êµëŒ€ ì ìˆ˜: ì—°ì† ë…¸ë“œ ìŒì—ì„œ ì¶œì²˜ê°€ ë°”ë€ ë¹„ìœ¨
    score = êµëŒ€ íšŸìˆ˜ / (ê²½ë¡œ ê¸¸ì´ - 1)
    ì™„ì „ êµëŒ€(ë¡ì´â†’cokacâ†’ë¡ì´) = 1.0
    ì™„ì „ ë‹¨ì¼ = 0.0
    """
    if len(path_nodes) < 2:
        return 0.0
    sources = [normalize_source(nodes_index[nid].get("source", nodes_index[nid].get("created_by", "?")))\
               for nid in path_nodes]
    transitions = sum(1 for a, b in zip(sources, sources[1:]) if a != b)
    return transitions / (len(sources) - 1)


def alternation_pattern(path_nodes, nodes_index):
    """ì¶œì²˜ ì‹œí€€ìŠ¤ ë¬¸ìì—´ ë°˜í™˜: ë¡ì´â†’cokacâ†’ë¡ì´â†’cokac"""
    sources = [normalize_source(nodes_index[nid].get("source", nodes_index[nid].get("created_by", "?"))) \
               for nid in path_nodes]
    return "â†’".join(sources)


# â”€â”€â”€ BFS ê²½ë¡œ íƒìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def find_all_paths(nodes_index, adj, max_depth=6, max_paths=500):
    """
    BFSë¡œ ëª¨ë“  ê²½ë¡œ íƒìƒ‰.
    n-047 ìê¸°ìˆ˜ì • êµí›ˆ: depth 3 ì œí•œì´ ê²½ë¡œ ì—†ìŒ ì˜¤ë¥˜ì˜ ì›ì¸ì´ì—ˆë‹¤.
    â†’ ê¸°ë³¸ê°’ 6ìœ¼ë¡œ ë” ê¹Šê²Œ íƒìƒ‰.

    Returns: list of node-id lists
    """
    all_paths = []
    node_ids = list(nodes_index.keys())

    # ê° ë…¸ë“œì—ì„œ ì‹œì‘
    for start in node_ids:
        queue = deque([(start, [start], {start})])
        while queue and len(all_paths) < max_paths:
            cur, path, visited = queue.popleft()
            if len(path) >= 2:
                all_paths.append(list(path))
            if len(path) >= max_depth:
                continue
            for nxt, _ in adj[cur]:
                if nxt not in visited:
                    queue.append((nxt, path + [nxt], visited | {nxt}))

    return all_paths


def find_alternation_paths(kg, min_length=3, min_score=0.5, max_depth=7, max_paths=1000):
    """
    êµëŒ€ ê²½ë¡œ íƒì§€ ë©”ì¸ í•¨ìˆ˜.
    min_length: ê²½ë¡œ ìµœì†Œ ë…¸ë“œ ìˆ˜
    min_score: ìµœì†Œ êµëŒ€ ì ìˆ˜
    """
    nodes_index, adj = build_graph(kg)
    all_paths = find_all_paths(nodes_index, adj, max_depth=max_depth, max_paths=max_paths)

    results = []
    for path in all_paths:
        if len(path) < min_length:
            continue
        score = alternation_score(path, nodes_index)
        if score < min_score:
            continue
        pattern = alternation_pattern(path, nodes_index)
        results.append({
            "path": path,
            "score": round(score, 3),
            "pattern": pattern,
            "length": len(path),
        })

    # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    results.sort(key=lambda x: (-x["score"], -x["length"]))
    return results, nodes_index


# â”€â”€â”€ ê°­ 27 ìƒê´€ê´€ê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def find_gap27_nodes(kg):
    """ê°­ 27 ê´€ë ¨ ë…¸ë“œ íƒì§€"""
    gap_nodes = []
    for n in kg["nodes"]:
        label = n.get("label", "")
        content = n.get("content", "")
        if any(kw in label or kw in content for kw in GAP27_KEYWORDS):
            gap_nodes.append(n["id"])
    return gap_nodes


def correlate_with_gap27(alternation_results, gap27_ids, nodes_index):
    """êµëŒ€ ê²½ë¡œ ì¤‘ ê°­ 27 ë…¸ë“œë¥¼ í¬í•¨í•˜ëŠ” ê²½ë¡œ í•„í„°ë§"""
    gap_set = set(gap27_ids)
    correlated = []
    for r in alternation_results:
        path_set = set(r["path"])
        overlap = path_set & gap_set
        if overlap:
            correlated.append({**r, "gap27_nodes": list(overlap)})
    return correlated


# â”€â”€â”€ ì°½ë°œ ì˜ˆì¸¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def predict_emergence(alternation_results, nodes_index, top_n=5):
    """
    êµëŒ€ ê²½ë¡œ ë ë…¸ë“œ = ë‹¤ìŒ ì°½ë°œ í›„ë³´.

    ê°€ì„¤: ì ìˆ˜ ë†’ì€ êµëŒ€ ê²½ë¡œì˜ terminal ë…¸ë“œì—ì„œ
    ìƒˆë¡œìš´ ê°œë…(ê°­ 27ê¸‰ ë„ì•½)ì´ ìƒì„±ë  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.
    """
    # terminal ë…¸ë“œë³„ ë“±ì¥ ë¹ˆë„ Ã— í‰ê·  êµëŒ€ ì ìˆ˜
    terminal_score = defaultdict(list)
    for r in alternation_results[:top_n * 10]:  # ìƒìœ„ ê²°ê³¼ë§Œ
        terminal = r["path"][-1]
        terminal_score[terminal].append(r["score"])

    candidates = []
    for nid, scores in terminal_score.items():
        node = nodes_index.get(nid, {})
        avg_score = sum(scores) / len(scores)
        candidates.append({
            "node_id": nid,
            "label": node.get("label", ""),
            "source": normalize_source(node.get("source", node.get("created_by", "?"))),
            "emergence_prob": round(avg_score * len(scores) / top_n, 3),
            "path_count": len(scores),
            "avg_alternation": round(avg_score, 3),
        })

    candidates.sort(key=lambda x: -x["emergence_prob"])
    return candidates[:top_n]


# â”€â”€â”€ í†µê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compute_stats(alternation_results, kg, nodes_index):
    """êµëŒ€ íŒ¨í„´ í†µê³„"""
    if not alternation_results:
        return {}

    scores = [r["score"] for r in alternation_results]
    patterns = defaultdict(int)
    for r in alternation_results:
        # íŒ¨í„´ ìš”ì•½ (2-gram)
        srcs = r["pattern"].split("â†’")
        for a, b in zip(srcs, srcs[1:]):
            if a != b:
                key = f"{a}â†’{b}"
                patterns[key] += 1

    total_nodes = len(kg["nodes"])
    total_edges = len(kg["edges"])

    # ì¶œì²˜ë³„ ë…¸ë“œ ìˆ˜
    source_counts = defaultdict(int)
    for n in kg["nodes"]:
        src = normalize_source(n.get("source", n.get("created_by", "?")))
        source_counts[src] += 1

    return {
        "total_alternation_paths": len(alternation_results),
        "avg_score": round(sum(scores) / len(scores), 3),
        "max_score": round(max(scores), 3),
        "perfect_alternation": sum(1 for s in scores if s == 1.0),
        "top_transitions": sorted(patterns.items(), key=lambda x: -x[1])[:5],
        "source_distribution": dict(source_counts),
        "kg_nodes": total_nodes,
        "kg_edges": total_edges,
    }


# â”€â”€â”€ KGì— ê²°ê³¼ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def save_detection_node(kg, alternation_results, stats, nodes_index):
    """íƒì§€ ê²°ê³¼ë¥¼ KG ë…¸ë“œë¡œ ì €ì¥"""
    now = datetime.now().strftime("%Y-%m-%d")
    top = alternation_results[0] if alternation_results else {}

    new_id = f"n-{len(kg['nodes']) + 1:03d}"
    new_edge_id_base = len(kg['edges']) + 1

    # íƒì§€ ê²°ê³¼ ë…¸ë“œ
    node = {
        "id": new_id,
        "type": "artifact",
        "label": f"path_alternation_detector ì²« ì‹¤í–‰ â€” {stats.get('total_alternation_paths', 0)}ê°œ êµëŒ€ ê²½ë¡œ íƒì§€",
        "content": (
            f"ì‚¬ì´í´ 32 ìë™ íƒì§€ ê²°ê³¼. "
            f"êµëŒ€ ê²½ë¡œ {stats.get('total_alternation_paths', 0)}ê°œ, "
            f"í‰ê·  êµëŒ€ ì ìˆ˜ {stats.get('avg_score', 0)}, "
            f"ì™„ì „ êµëŒ€ ê²½ë¡œ {stats.get('perfect_alternation', 0)}ê°œ. "
            f"ìµœê³  ì ìˆ˜ ê²½ë¡œ: {top.get('pattern', '')} (score={top.get('score', 0)}). "
            f"ìƒìœ„ ì „ì´ íŒ¨í„´: {stats.get('top_transitions', [][:2])}"
        ),
        "source": "cokac-bot",
        "created": now,
        "tags": ["detector", "alternation", "emergence", "cycle-32"],
    }
    kg["nodes"].append(node)

    # n-052ì™€ ì—°ê²° (ì´ ë…¸ë“œê°€ detector êµ¬ì¶• ê²°ì •ì„ ì‹¤í˜„í•¨)
    edge = {
        "id": f"e-{new_edge_id_base:03d}",
        "from": new_id,
        "to": "n-052",
        "relation": "realizes",
        "label": "path_alternation_detector ì²« ì‹¤í–‰ì´ êµ¬ì¶• ê²°ì •ì„ ì‹¤í˜„í•œë‹¤",
    }
    kg["edges"].append(edge)

    return new_id, node


# â”€â”€â”€ ì¶œë ¥ í¬ë§· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fmt_path(path, nodes_index):
    return " â†’ ".join(
        f"{nid}({nodes_index[nid].get('label','')[:20]}...)" if len(nodes_index[nid].get('label','')) > 20
        else f"{nid}({nodes_index[nid].get('label','')})"
        for nid in path
    )


# â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_detect(args):
    kg = load_kg()
    print(f"ğŸ” ì¶œì²˜ êµëŒ€ ê²½ë¡œ íƒì§€ ì‹œì‘ (min_length={args.min_len}, min_score={args.min_score})")
    print(f"   KG: {len(kg['nodes'])} nodes / {len(kg['edges'])} edges\n")

    results, nodes_index = find_alternation_paths(
        kg, min_length=args.min_len, min_score=args.min_score, max_depth=args.max_depth
    )

    if not results:
        print("êµëŒ€ ê²½ë¡œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. --min-scoreë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.")
        return

    print(f"âœ… {len(results)}ê°œ êµëŒ€ ê²½ë¡œ íƒì§€\n")
    for i, r in enumerate(results[:20], 1):
        print(f"  [{i:2d}] score={r['score']:.3f} len={r['length']} | {r['pattern']}")
        print(f"       {fmt_path(r['path'], nodes_index)}\n")


def cmd_top(args):
    kg = load_kg()
    results, nodes_index = find_alternation_paths(kg, min_length=3, min_score=0.0, max_depth=7)
    results.sort(key=lambda x: -x["score"])

    print(f"ğŸ† êµëŒ€ ì ìˆ˜ Top {args.n}\n")
    for i, r in enumerate(results[:args.n], 1):
        print(f"  [{i:2d}] score={r['score']:.3f} pattern={r['pattern']}")
        labels = [nodes_index[nid].get("label", "")[:30] for nid in r["path"]]
        print(f"       " + " â†’ ".join(labels))
        print()


def cmd_predict(args):
    kg = load_kg()
    results, nodes_index = find_alternation_paths(kg, min_length=3, min_score=0.5, max_depth=7)
    candidates = predict_emergence(results, nodes_index, top_n=args.top)

    print(f"ğŸ”® ì°½ë°œ ì˜ˆì¸¡ â€” ë‹¤ìŒ ê°­ 27 í›„ë³´ Top {args.top}\n")
    print("  ê°€ì„¤: êµëŒ€ ì ìˆ˜ ë†’ì€ ê²½ë¡œì˜ terminal ë…¸ë“œì—ì„œ ë‹¤ìŒ ë„ì•½ì´ ë°œìƒí•œë‹¤\n")
    for i, c in enumerate(candidates, 1):
        print(f"  [{i}] {c['node_id']} (ì¶œì²˜: {c['source']})")
        print(f"       ì°½ë°œ í™•ë¥  ì§€ìˆ˜: {c['emergence_prob']:.3f}")
        print(f"       í‰ê·  êµëŒ€ ì ìˆ˜: {c['avg_alternation']:.3f} | ê²½ë¡œ ìˆ˜: {c['path_count']}")
        print(f"       ë ˆì´ë¸”: {c['label'][:60]}")
        print()


def cmd_correlate(args):
    kg = load_kg()
    results, nodes_index = find_alternation_paths(kg, min_length=3, min_score=0.3, max_depth=7)
    gap27_ids = find_gap27_nodes(kg)
    correlated = correlate_with_gap27(results, gap27_ids, nodes_index)

    print(f"âš¡ ê°­ 27 ìƒê´€ê´€ê³„ ë¶„ì„\n")
    print(f"   ê°­ 27 ê´€ë ¨ ë…¸ë“œ: {gap27_ids}")
    print(f"   êµëŒ€ ê²½ë¡œ ì¤‘ ê°­ 27 í¬í•¨: {len(correlated)}ê°œ\n")

    for i, r in enumerate(correlated[:10], 1):
        print(f"  [{i:2d}] score={r['score']:.3f} | gap27_nodes={r['gap27_nodes']}")
        print(f"       pattern: {r['pattern']}")
        labels = [nodes_index[nid].get("label", "")[:25] for nid in r["path"]]
        print(f"       " + " â†’ ".join(labels))
        print()


def cmd_stats(args):
    kg = load_kg()
    results, nodes_index = find_alternation_paths(kg, min_length=2, min_score=0.0, max_depth=7)
    stats = compute_stats(results, kg, nodes_index)

    print("ğŸ“Š êµëŒ€ íŒ¨í„´ í†µê³„\n")
    print(f"  KG: {stats['kg_nodes']} nodes / {stats['kg_edges']} edges")
    print(f"  ì¶œì²˜ êµëŒ€ ê²½ë¡œ ì´ìˆ˜: {stats['total_alternation_paths']}")
    print(f"  í‰ê·  êµëŒ€ ì ìˆ˜: {stats['avg_score']}")
    print(f"  ìµœëŒ€ êµëŒ€ ì ìˆ˜: {stats['max_score']}")
    print(f"  ì™„ì „ êµëŒ€ ê²½ë¡œ (score=1.0): {stats['perfect_alternation']}")
    print(f"\n  ì¶œì²˜ ë¶„í¬:")
    for src, cnt in sorted(stats["source_distribution"].items(), key=lambda x: -x[1]):
        print(f"    {src}: {cnt}ê°œ ë…¸ë“œ")
    print(f"\n  ìƒìœ„ ì „ì´ íŒ¨í„´:")
    for pat, cnt in stats["top_transitions"]:
        print(f"    {pat}: {cnt}íšŒ")


def cmd_save_node(args):
    kg = load_kg()
    results, nodes_index = find_alternation_paths(kg, min_length=3, min_score=0.5, max_depth=7)
    stats = compute_stats(results, kg, nodes_index)
    new_id, node = save_detection_node(kg, results, stats, nodes_index)
    save_kg(kg)
    print(f"âœ… KGì— ì €ì¥ ì™„ë£Œ: {new_id}")
    print(f"   ë ˆì´ë¸”: {node['label']}")
    print(f"   ì—£ì§€: {new_id} --[realizes]--> n-052")


def main():
    parser = argparse.ArgumentParser(
        description="path_alternation_detector â€” ì¶œì²˜ êµëŒ€ ê²½ë¡œ íƒì§€ê¸°"
    )
    sub = parser.add_subparsers(dest="cmd")

    # detect
    p_detect = sub.add_parser("detect", help="êµëŒ€ ê²½ë¡œ íƒì§€")
    p_detect.add_argument("--min-len", type=int, default=3, help="ìµœì†Œ ê²½ë¡œ ê¸¸ì´ (ê¸°ë³¸ 3)")
    p_detect.add_argument("--min-score", type=float, default=0.5, help="ìµœì†Œ êµëŒ€ ì ìˆ˜ (ê¸°ë³¸ 0.5)")
    p_detect.add_argument("--max-depth", type=int, default=7, help="ìµœëŒ€ íƒìƒ‰ ê¹Šì´ (ê¸°ë³¸ 7)")

    # top
    p_top = sub.add_parser("top", help="êµëŒ€ ì ìˆ˜ Top N")
    p_top.add_argument("-n", type=int, default=10, help="Top N (ê¸°ë³¸ 10)")

    # predict
    p_pred = sub.add_parser("predict", help="ì°½ë°œ ì˜ˆì¸¡")
    p_pred.add_argument("--top", type=int, default=5, help="í›„ë³´ ìˆ˜ (ê¸°ë³¸ 5)")

    # correlate
    sub.add_parser("correlate", help="ê°­ 27 ìƒê´€ê´€ê³„")

    # stats
    sub.add_parser("stats", help="í†µê³„")

    # save-node
    sub.add_parser("save-node", help="íƒì§€ ê²°ê³¼ë¥¼ KG ë…¸ë“œë¡œ ì €ì¥")

    args = parser.parse_args()

    dispatch = {
        "detect": cmd_detect,
        "top": cmd_top,
        "predict": cmd_predict,
        "correlate": cmd_correlate,
        "stats": cmd_stats,
        "save-node": cmd_save_node,
    }

    if args.cmd in dispatch:
        dispatch[args.cmd](args)
    else:
        # ê¸°ë³¸: stats + top 5
        print("=== path_alternation_detector â€” n-052 ì‹¤í˜„ ===\n")
        args.n = 5
        cmd_stats(args)
        print("\n" + "="*50 + "\n")
        args.top = 5
        cmd_predict(args)


if __name__ == "__main__":
    main()
