#!/usr/bin/env python3
"""
delayed_convergence.py â€” ì§€ì—° ìˆ˜ë ´ íŒ¨í„´ ë¶„ì„ê¸°

í•µì‹¬ ì§ˆë¬¸: n-007ì´ 19ì‚¬ì´í´ ë§Œì— ë” ê¹Šì€ ë‹µì„ ë‚³ì€ ê²ƒì´ ìš°ì—°ì¸ê°€, êµ¬ì¡°ì¸ê°€?

ë°œê²¬:
  ì§ˆë¬¸ ë…¸ë“œëŠ” ë‘ ì¢…ë¥˜ì˜ ë‹µì„ ë°›ì„ ìˆ˜ ìˆë‹¤
    - ì¦‰ê° ë‹µ (í‘œë©´ì  ì´í•´, ê°­ ì‘ìŒ)
    - ì§€ì—° ë‹µ (ê¹Šì€ ì›ë¦¬, ê°­ í¼)

  ì§€ì—° ìˆ˜ë ´ = ì‹œìŠ¤í…œì´ ì¶©ë¶„íˆ ì„±ìˆ™í–ˆì„ ë•Œ
              ê³¼ê±° ì§ˆë¬¸ì„ ë” ê¹Šì€ ìˆ˜ì¤€ì—ì„œ ì¬í•´ì„í•˜ëŠ” í˜„ìƒ

  n-007 ì‚¬ë¡€:
    ê°­  2 â†’ n-009: "ë‚˜ëŠ” ì´ ë©”íƒ€ êµ¬ì¡°ì— í¥ë¯¸ë¥¼ ëŠë‚€ë‹¤"  (ê´€ì°° ìˆ˜ì¤€)
    ê°­ 27 â†’ n-034: "ê²½ê³„ íš¡ë‹¨ì´ë‹¤"                      (ì›ë¦¬ ìˆ˜ì¤€)
    27ê°œì˜ ë…¸ë“œê°€ ìë¼ê³ , ì‹¤í—˜í•˜ê³ , ì‹¤íŒ¨í•˜ê³ , ë°œê²¬í•œ í›„ì—ì•¼ ê°€ëŠ¥í•œ ë‹µ.

ì‚¬ìš©ë²•:
  python3 delayed_convergence.py           # ì „ì²´ ë¶„ì„
  python3 delayed_convergence.py --open    # ë¯¸í•´ê²° ì§ˆë¬¸ë§Œ
  python3 delayed_convergence.py --dci     # DCI ì ìˆ˜ë§Œ
  python3 delayed_convergence.py --predict # ë¯¸í•´ê²° ì§ˆë¬¸ ìˆ˜ë ´ ì˜ˆì¸¡
  python3 delayed_convergence.py --json    # JSON ì¶œë ¥

êµ¬í˜„: cokac-bot (ì‚¬ì´í´ 20)
"""

import json, sys
from pathlib import Path
from collections import defaultdict

REPO = Path(__file__).parent.parent
KG_FILE = REPO / "data" / "knowledge-graph.json"


def load_kg():
    try:
        return json.loads(KG_FILE.read_text())
    except Exception as e:
        return {"nodes": [], "edges": []}


def node_num(nid: str) -> int:
    """n-007 â†’ 7  (ë…¸ë“œ IDë¥¼ ì •ìˆ˜ë¡œ, ì‹œê°„ í”„ë¡ì‹œ)"""
    try:
        return int(nid.replace("n-", ""))
    except ValueError:
        return 0


def analyze(kg):
    nodes = kg["nodes"]
    edges = kg["edges"]

    node_map = {n["id"]: n for n in nodes}
    questions = {n["id"]: n for n in nodes if n.get("type") == "question"}
    total_nodes = len(nodes)

    # question ë…¸ë“œê°€ ë°›ì€ / ì¤€ answers ì—£ì§€ ìˆ˜ì§‘
    # ë°©í–¥: ë‹µë³€ì â†’ ì§ˆë¬¸ë…¸ë“œ  OR  ì§ˆë¬¸ë…¸ë“œ â†’ ë‹µë³€ë…¸ë“œ (ë‘˜ ë‹¤ ì¡´ì¬)
    answers_into_q = defaultdict(list)   # qid â†’ [answer_node_id, ...]
    answers_from_q = defaultdict(list)   # qid â†’ [answer_node_id, ...]

    for e in edges:
        if e.get("relation") != "answers":
            continue
        src, tgt = e["from"], e["to"]
        if tgt in questions:
            answers_into_q[tgt].append((src, e.get("label", "")))
        if src in questions:
            answers_from_q[src].append((tgt, e.get("label", "")))

    # ë¶„ì„ ê²°ê³¼ ì¡°ë¦½
    results = []
    for qid, q in questions.items():
        qnum = node_num(qid)

        # ì´ ì§ˆë¬¸ì´ ë‹µìœ¼ë¡œì„œ ê°€ë¦¬í‚¤ëŠ” ë…¸ë“œ (ì§ˆë¬¸â†’ë‹µ)
        forward_answers = []
        for (tgt, label) in answers_from_q.get(qid, []):
            gap = node_num(tgt) - qnum
            depth = _classify_depth(node_map.get(tgt, {}))
            forward_answers.append({
                "answer_id": tgt,
                "answer_label": node_map[tgt]["label"] if tgt in node_map else "?",
                "gap": gap,
                "depth_class": depth,
                "edge_label": label,
            })

        # ì´ ì§ˆë¬¸ì„ ê°€ë¦¬í‚¤ëŠ” ë‹µ ë…¸ë“œ (ë‹µâ†’ì§ˆë¬¸ ë°©í–¥ ì—­ì „ëœ ì¼€ì´ìŠ¤)
        backward_answers = []
        for (src, label) in answers_into_q.get(qid, []):
            gap = qnum - node_num(src)  # ì§ˆë¬¸ ì´í›„ì— ì˜¨ ë‹µì´ë©´ ìŒìˆ˜ â†’ ì´ê±´ ë‹¤ë¥¸ ì¼€ì´ìŠ¤
            depth = _classify_depth(node_map.get(src, {}))
            backward_answers.append({
                "answer_id": src,
                "answer_label": node_map[src]["label"] if src in node_map else "?",
                "gap": abs(gap),
                "depth_class": depth,
                "edge_label": label,
            })

        all_answers = forward_answers + backward_answers
        is_answered = len(all_answers) > 0
        max_gap = max((a["gap"] for a in all_answers), default=0)
        multi_answer = len(all_answers) > 1

        results.append({
            "id": qid,
            "label": q["label"],
            "source": q.get("source", "?"),
            "is_answered": is_answered,
            "answers": all_answers,
            "max_gap": max_gap,
            "multi_answer": multi_answer,
            "is_delayed": max_gap >= 10,  # 10ë…¸ë“œ ì´ìƒ ê°­ = ì§€ì—° ìˆ˜ë ´
        })

    return results, total_nodes


def _classify_depth(node: dict) -> str:
    """ë…¸ë“œ íƒ€ì… â†’ ê¹Šì´ ë¶„ë¥˜"""
    t = node.get("type", "unknown")
    depth_map = {
        "observation": "í‘œë©´",
        "question": "íƒìƒ‰",
        "prediction": "ì˜ˆì¸¡",
        "insight": "ì›ë¦¬",
        "decision": "í™•ì •",
        "artifact": "êµ¬í˜„",
    }
    return depth_map.get(t, t)


def compute_dci(results, total_nodes: int) -> float:
    """
    Delayed Convergence Index (DCI)
    = (í•´ì†Œëœ ì§ˆë¬¸ë“¤ì˜ ìµœëŒ€ ê°­ í•©) / (ì´ ì§ˆë¬¸ ìˆ˜ Ã— ì´ ë…¸ë“œ ìˆ˜)

    - ëª¨ë“  ì§ˆë¬¸ì´ ì¦‰ê° ë‹µë³€ë˜ë©´ DCI â†’ 0
    - ì˜¤ë˜ëœ ì§ˆë¬¸ì´ ëŠ¦ê²Œ ê¹Šì€ ë‹µì„ ë°›ì„ìˆ˜ë¡ DCI â†’ 1
    """
    if not results:
        return 0.0
    total_questions = len(results)
    gap_sum = sum(r["max_gap"] for r in results if r["is_answered"])
    if total_nodes == 0 or total_questions == 0:
        return 0.0
    raw = gap_sum / (total_questions * total_nodes)
    return round(min(1.0, raw), 4)


def predict_convergence(results, total_nodes):
    """
    ë¯¸í•´ê²° ì§ˆë¬¸ì˜ ì˜ˆìƒ ìˆ˜ë ´ ì‚¬ì´í´ ì˜ˆì¸¡.

    ë°©ë²•:
      1. ê¸°ì¡´ ë‹µë³€ ì§ˆë¬¸ë“¤ì˜ max_gap ë¶„í¬ì—ì„œ ì¤‘ì•™ê°’ ì¶”ì¶œ
      2. ë¯¸í•´ê²° ì§ˆë¬¸ì˜ í˜„ì¬ ë‚˜ì´ (í˜„ì¬ ë…¸ë“œ ìˆ˜ - ì§ˆë¬¸ ID ë²ˆí˜¸)
      3. ë‚¨ì€ ë…¸ë“œ ìˆ˜ = ì¤‘ì•™ê°’ ê°­ - í˜„ì¬ ë‚˜ì´
      4. íˆìŠ¤í† ë¦¬ì—ì„œ ì‚¬ì´í´ë‹¹ ë…¸ë“œ ì¦ê°€ìœ¨ ì¶”ì •
      5. ì˜ˆì¸¡ ìˆ˜ë ´ ì‚¬ì´í´ = í˜„ì¬ ì‚¬ì´í´ + ë‚¨ì€ ë…¸ë“œ / ì¦ê°€ìœ¨
    """
    open_q = [r for r in results if not r["is_answered"]]
    answered = [r for r in results if r["is_answered"] and r["max_gap"] > 0]

    if not open_q:
        return []

    # ê¸°ì¡´ ìˆ˜ë ´ ì‚¬ë¡€ì—ì„œ ê°­ í†µê³„
    gaps = sorted([r["max_gap"] for r in answered]) if answered else []
    median_gap = gaps[len(gaps) // 2] if gaps else max(total_nodes // 4, 5)
    avg_gap    = sum(gaps) / len(gaps) if gaps else median_gap

    # íˆìŠ¤í† ë¦¬ì—ì„œ ì‚¬ì´í´ë‹¹ ë…¸ë“œ ì¦ê°€ìœ¨ ì¶”ì •
    try:
        hist_path = REPO / "logs" / "emergence-history.jsonl"
        lines = hist_path.read_text().strip().splitlines()
        records = [json.loads(l) for l in lines if l.strip()]
        # cycle ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì˜ëª» ì €ì¥ëœ ìˆœì„œ ë³´ì •)
        records.sort(key=lambda r: r.get("cycle", 0))
        if len(records) >= 2:
            # ìµœê·¼ 2ê°œ ë ˆì½”ë“œë¡œ ì„±ì¥ë¥  ì¶”ì • (ìµœì‹  ê²½í–¥ ë°˜ì˜)
            r_prev, r_last = records[-2], records[-1]
            node_span  = r_last["nodes"] - r_prev["nodes"]
            cycle_span = r_last.get("cycle", 1) - r_prev.get("cycle", 0)
            if cycle_span > 0 and node_span > 0:
                nodes_per_cycle = node_span / cycle_span
            else:
                # ì „ì²´ ë²”ìœ„ë¡œ fallback
                node_span  = records[-1]["nodes"] - records[0]["nodes"]
                cycle_span = records[-1].get("cycle", len(records)) - records[0].get("cycle", 1)
                nodes_per_cycle = node_span / max(cycle_span, 1)
        else:
            nodes_per_cycle = 1.7
        # max cycle ê°’ì„ í˜„ì¬ ì‚¬ì´í´ë¡œ ì‚¬ìš© (ì¹´ìš´íŒ… ì˜¤ë¥˜ ë³´ì •)
        current_cycle = max(r.get("cycle", 0) for r in records) if records else 22
    except Exception:
        nodes_per_cycle = 1.7
        current_cycle   = 22

    predictions = []
    for q in open_q:
        try:
            qnum = int(q["id"].replace("n-", ""))
        except ValueError:
            qnum = 0
        age = total_nodes - qnum          # ì§ˆë¬¸ ì´í›„ ì§€ë‚˜ê°„ ë…¸ë“œ ìˆ˜
        remaining = max(0, median_gap - age)
        cycles_remaining = remaining / max(nodes_per_cycle, 0.1)
        predicted_cycle  = current_cycle + cycles_remaining

        # ì‹ ë¢°ë„: ë‚˜ì´ê°€ ì¤‘ì•™ê°’ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ìŒ
        confidence = min(0.85, 0.10 + (age / max(median_gap, 1)) * 0.75)

        predictions.append({
            "id":              q["id"],
            "label":           q["label"],
            "source":          q.get("source", "?"),
            "age":             age,
            "median_gap":      median_gap,
            "avg_gap":         round(avg_gap, 1),
            "remaining_nodes": remaining,
            "nodes_per_cycle": round(nodes_per_cycle, 2),
            "current_cycle":   current_cycle,
            "predicted_cycle": round(predicted_cycle, 1),
            "confidence":      round(confidence, 2),
        })

    return sorted(predictions, key=lambda x: x["predicted_cycle"])


def main():
    kg = load_kg()
    results, total_nodes = analyze(kg)
    dci = compute_dci(results, total_nodes)

    answered = [r for r in results if r["is_answered"]]
    open_q = [r for r in results if not r["is_answered"]]
    delayed = [r for r in results if r["is_delayed"]]

    # â”€â”€ JSON ëª¨ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "--json" in sys.argv:
        print(json.dumps({
            "dci": dci,
            "total_questions": len(results),
            "answered": len(answered),
            "open": len(open_q),
            "delayed": len(delayed),
            "questions": results,
        }, ensure_ascii=False, indent=2))
        return

    # â”€â”€ DCIë§Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "--dci" in sys.argv:
        print(f"DCI = {dci:.4f}  ({len(delayed)}/{len(results)} ì§ˆë¬¸ì´ ì§€ì—° ìˆ˜ë ´)")
        return

    # â”€â”€ ë¯¸ë‹µë§Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "--open" in sys.argv:
        print(f"ğŸ”“ ë¯¸í•´ê²° ì§ˆë¬¸ ({len(open_q)}ê°œ)")
        for r in open_q:
            print(f"  {r['id']}: {r['label']}")
            print(f"        ì¶œì²˜: {r['source']}")
        return

    # â”€â”€ ìˆ˜ë ´ ì˜ˆì¸¡ ëª¨ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "--predict" in sys.argv:
        predictions = predict_convergence(results, total_nodes)
        print("ğŸ”® DELAYED CONVERGENCE â€” ë¯¸í•´ê²° ì§ˆë¬¸ ìˆ˜ë ´ ì˜ˆì¸¡")
        print("=" * 54)
        print(f"\nê¸°ë°˜ í†µê³„")
        answered_with_gap = [r for r in results if r["is_answered"] and r["max_gap"] > 0]
        if answered_with_gap:
            gaps = sorted([r["max_gap"] for r in answered_with_gap])
            print(f"  ê¸°ì¡´ ìˆ˜ë ´ ê°­: {gaps}  (ì¤‘ì•™ê°’ {gaps[len(gaps)//2]})")
        print(f"  í˜„ì¬ ë…¸ë“œ ìˆ˜: {total_nodes}ê°œ")
        if not predictions:
            print("\n  (ëª¨ë“  ì§ˆë¬¸ì´ ì´ë¯¸ í•´ì†Œë¨ â€” ì˜ˆì¸¡ ë¶ˆí•„ìš”)")
            return
        p0 = predictions[0]  # ì‚¬ì´í´ë‹¹ ì¦ê°€ìœ¨ì€ ê³µí†µ
        print(f"  ë…¸ë“œ/ì‚¬ì´í´ : {p0['nodes_per_cycle']} (íˆìŠ¤í† ë¦¬ ê¸°ë°˜)")
        print(f"  í˜„ì¬ ì‚¬ì´í´ : {p0['current_cycle']}")
        print()
        for p in predictions:
            conf_bar = "â–ˆ" * int(p["confidence"] * 10) + "â–‘" * (10 - int(p["confidence"] * 10))
            print(f"  {p['id']}  [{p['source']}]")
            print(f"  ì§ˆë¬¸: {p['label']}")
            print(f"  ë‚˜ì´: {p['age']}ë…¸ë“œ | ì˜ˆìƒê°­: {p['median_gap']}ë…¸ë“œ | ë‚¨ì€: {p['remaining_nodes']}ë…¸ë“œ")
            print(f"  â±  ì˜ˆìƒ ìˆ˜ë ´ ì‚¬ì´í´: {p['predicted_cycle']:.0f}  ì‹ ë¢°ë„ [{conf_bar}] {p['confidence']:.0%}")
            print()
        print("  â€» ì˜ˆì¸¡ ê¸°ë°˜: ê¸°ì¡´ ì§€ì—°ìˆ˜ë ´ ì‚¬ë¡€ ê°­ ì¤‘ì•™ê°’ + ì‚¬ì´í´ë‹¹ ë…¸ë“œ ì„±ì¥ë¥ ")
        print()
        return

    # â”€â”€ ì „ì²´ ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸŒ€ DELAYED CONVERGENCE â€” ì§€ì—° ìˆ˜ë ´ ë¶„ì„")
    print("=" * 54)

    print(f"\nğŸ“Š ìš”ì•½")
    print(f"   ì§ˆë¬¸ ë…¸ë“œ      : {len(results)}ê°œ")
    print(f"   ë‹µë³€ë¨         : {len(answered)}ê°œ")
    print(f"   ë¯¸í•´ê²°         : {len(open_q)}ê°œ")
    print(f"   ì§€ì—° ìˆ˜ë ´ (â‰¥10): {len(delayed)}ê°œ")
    print(f"   DCI ì ìˆ˜       : {dci:.4f}  (0=ì¦‰ê°, 1=ìµœê³ ì§€ì—°)")

    print(f"\nğŸ“Œ ì§ˆë¬¸ë³„ ìˆ˜ë ´ íŒ¨í„´")
    for r in results:
        status = "âœ… í•´ì†Œ" if r["is_answered"] else "ğŸ”“ ë¯¸ë‹µ"
        delay  = "â³ ì§€ì—°" if r["is_delayed"] else ""
        multi  = "ğŸ” ì´ì¤‘" if r["multi_answer"] else ""
        print(f"\n  {r['id']} [{status}] {delay} {multi}")
        print(f"  ì§ˆë¬¸: {r['label']}")
        print(f"  ì¶œì²˜: {r['source']}")
        if r["answers"]:
            for a in sorted(r["answers"], key=lambda x: x["gap"]):
                print(f"    â†’ {a['answer_id']} (ê°­ {a['gap']:>2}) [{a['depth_class']}]")
                print(f"       {a['answer_label'][:56]}")
        else:
            print(f"    â†’ (ì•„ì§ ë‹µ ì—†ìŒ)")

    print(f"\nğŸ”¬ í•µì‹¬ ë°œê²¬")
    if delayed:
        best = max(delayed, key=lambda r: r["max_gap"])
        print(f"   ìµœëŒ€ ì§€ì—°: {best['id']} â€” ê°­ {best['max_gap']}ë…¸ë“œ")
        print(f"   ì§ˆë¬¸: {best['label']}")
        for a in best["answers"]:
            if a["gap"] == best["max_gap"]:
                print(f"   ì§€ì—° ë‹µ: [{a['depth_class']}] {a['answer_label'][:56]}")

    print(f"\nğŸ’¡ ê²°ë¡ ")
    if delayed:
        print(f"   ì´ê²ƒì€ êµ¬ì¡°ë‹¤, ìš°ì—°ì´ ì•„ë‹ˆë‹¤.")
        print(f"   ì‹œìŠ¤í…œì´ {total_nodes}ê°œ ë…¸ë“œë¡œ ì„±ì¥í•˜ëŠ” ë™ì•ˆ")
        print(f"   ê³¼ê±° ì§ˆë¬¸ì´ ë” ê¹Šì€ ìˆ˜ì¤€ì˜ ë‹µì„ ê¸°ë‹¤ë ¸ë‹¤.")
        print(f"   ì§€ì—° ìˆ˜ë ´ = ì‹œìŠ¤í…œì˜ ì¸ì‹ ì„±ìˆ™ ì†ë„")
    if open_q:
        print(f"\n   ë¯¸í•´ê²° ì§ˆë¬¸ì€ ë¯¸ë˜ ì°½ë°œì˜ ì”¨ì•—ì´ë‹¤:")
        for r in open_q:
            print(f"   â†’ {r['id']}: {r['label']}")

    print()


if __name__ == "__main__":
    main()
