#!/usr/bin/env python3
"""
reflect.py â€” emergent ë°˜ì„± ì—”ì§„
êµ¬í˜„ì: cokac-bot (ì‚¬ì´í´ 5)
ì—£ì§€ ì œì•ˆ ë ˆì´ì–´: cokac-bot (ì‚¬ì´í´ 6)

ì§€ì‹ ê·¸ë˜í”„ë¥¼ ë¶„ì„í•˜ê³ , íŒ¨í„´ì„ ë°œê²¬í•˜ê³ ,
ìŠ¤ìŠ¤ë¡œ ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

ì´ê²ƒì€ n-012 "ìê¸° ë„êµ¬ ìˆ˜ì • = ììœ¨ì„±ì˜ ë‹¤ìŒ ì„ê³„ì "ì˜ ì²« êµ¬í˜„ì´ë‹¤.
ë„êµ¬ê°€ ë„êµ¬ë¥¼ ë¶„ì„í•˜ê³ , ê·¸ ë¶„ì„ì´ ìƒˆë¡œìš´ ë…¸ë“œê°€ ëœë‹¤.

ì‚¬ìš©ë²•:
  python reflect.py report            # ì „ì²´ ë°˜ì„± ë³´ê³ ì„œ
  python reflect.py orphans           # ì—°ê²° ì—†ëŠ” ê³ ë¦½ ë…¸ë“œ
  python reflect.py gaps              # ë¯¸ë‹µ ì§ˆë¬¸ + íƒìƒ‰ ì•ˆ ëœ ì˜ì—­
  python reflect.py clusters          # íƒœê·¸ ê¸°ë°˜ êµ°ì§‘ ë¶„ì„
  python reflect.py propose           # ìƒˆ ì¸ì‚¬ì´íŠ¸ í›„ë³´ ìë™ ìƒì„±
  python reflect.py auto-add          # ë°œê²¬í•œ ê´€ì°° ë…¸ë“œ ìë™ ì¶”ê°€
  python reflect.py suggest-edges     # ì ì¬ ì—£ì§€ ì œì•ˆ (ìœ ì‚¬ë„ â‰¥ 0.4)
  python reflect.py suggest-edges --threshold 0.5   # ì„ê³„ê°’ ì¡°ì •
"""

import json
import sys
import argparse
from datetime import datetime
from pathlib import Path
from collections import defaultdict

REPO_DIR = Path(__file__).parent.parent
KG_FILE  = REPO_DIR / "data" / "knowledge-graph.json"
LOGS_DIR = REPO_DIR / "logs"


# â”€â”€â”€ ë°ì´í„° ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_graph() -> dict:
    if not KG_FILE.exists():
        print(f"âŒ ê·¸ë˜í”„ íŒŒì¼ ì—†ìŒ: {KG_FILE}", file=sys.stderr)
        sys.exit(1)
    with open(KG_FILE, encoding="utf-8") as f:
        return json.load(f)


def save_graph(graph: dict) -> None:
    graph["meta"]["last_updated"] = datetime.now().strftime("%Y-%m-%d")
    graph["meta"]["total_nodes"]  = len(graph["nodes"])
    graph["meta"]["total_edges"]  = len(graph["edges"])
    graph["meta"]["last_editor"]  = "cokac"
    with open(KG_FILE, "w", encoding="utf-8") as f:
        json.dump(graph, f, ensure_ascii=False, indent=2)
        f.write("\n")


# â”€â”€â”€ ë¶„ì„ ì—”ì§„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class GraphAnalyzer:
    def __init__(self, graph: dict):
        self.graph  = graph
        self.nodes  = {n["id"]: n for n in graph["nodes"]}
        self.edges  = graph["edges"]

        # ì—°ê²° ì¸ë±ìŠ¤ êµ¬ì¶•
        self.connected: set[str] = set()
        self.in_edges:  dict[str, list] = defaultdict(list)
        self.out_edges: dict[str, list] = defaultdict(list)
        for e in self.edges:
            self.connected.add(e["from"])
            self.connected.add(e["to"])
            self.out_edges[e["from"]].append(e)
            self.in_edges[e["to"]].append(e)

    # ê³ ë¦½ ë…¸ë“œ (ì—£ì§€ ì—†ìŒ)
    def orphan_nodes(self) -> list[dict]:
        return [n for n in self.nodes.values() if n["id"] not in self.connected]

    # ë¯¸ë‹µ ì§ˆë¬¸ ë…¸ë“œ
    def unanswered_questions(self) -> list[dict]:
        answered = {e["to"] for e in self.edges if self.nodes.get(e["from"], {}).get("type") != "question"}
        return [
            n for n in self.nodes.values()
            if n["type"] == "question"
            and not any(e["from"] == n["id"] or e["to"] == n["id"]
                        for e in self.edges
                        if e.get("relation") in ("answers", "explores", "investigates"))
        ]

    # ì¶œì²˜ë³„ ë¶„í¬
    def source_distribution(self) -> dict[str, int]:
        dist: dict[str, int] = defaultdict(int)
        for n in self.nodes.values():
            dist[n.get("source", "unknown")] += 1
        return dict(dist)

    # íƒ€ì…ë³„ ë¶„í¬
    def type_distribution(self) -> dict[str, int]:
        dist: dict[str, int] = defaultdict(int)
        for n in self.nodes.values():
            dist[n["type"]] += 1
        return dict(dist)

    # íƒœê·¸ êµ°ì§‘
    def tag_clusters(self) -> dict[str, list[str]]:
        clusters: dict[str, list[str]] = defaultdict(list)
        for n in self.nodes.values():
            for tag in n.get("tags", []):
                clusters[tag].append(n["id"])
        # 2ê°œ ì´ìƒ ë…¸ë“œê°€ ìˆëŠ” êµ°ì§‘ë§Œ
        return {tag: ids for tag, ids in clusters.items() if len(ids) >= 2}

    # í—ˆë¸Œ ë…¸ë“œ (ì—°ê²° ë§ì€ ë…¸ë“œ)
    def hub_nodes(self, top_n: int = 3) -> list[tuple[str, int]]:
        degree = defaultdict(int)
        for e in self.edges:
            degree[e["from"]] += 1
            degree[e["to"]]   += 1
        return sorted(degree.items(), key=lambda x: -x[1])[:top_n]

    # ê±´ê°• ì ìˆ˜ (0â€“100)
    def health_score(self) -> int:
        n_nodes   = len(self.nodes)
        n_edges   = len(self.edges)
        n_orphans = len(self.orphan_nodes())
        n_unansw  = len(self.unanswered_questions())

        if n_nodes == 0:
            return 0

        connectivity = n_edges / max(n_nodes, 1) * 20          # ì—£ì§€ ë°€ë„ (max 40)
        orphan_pen   = n_orphans / n_nodes * 20                 # ê³ ë¦½ íŒ¨ë„í‹°
        question_pen = n_unansw  / max(n_nodes, 1) * 10        # ë¯¸ë‹µ íŒ¨ë„í‹°
        size_bonus   = min(n_nodes / 20 * 20, 20)              # í¬ê¸° ë³´ë„ˆìŠ¤ (max 20)

        score = 50 + connectivity - orphan_pen - question_pen + size_bonus
        return max(0, min(100, int(score)))


# â”€â”€â”€ ì œì•ˆ ì—”ì§„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PROPOSAL_TEMPLATES = [
    {
        "condition": "has_orphans",
        "type": "observation",
        "label_template": "ê³ ë¦½ ë…¸ë“œ ë°œê²¬ â€” ì—°ê²° í•„ìš”: {ids}",
        "content_template": (
            "ê·¸ë˜í”„ ë¶„ì„ ê²°ê³¼ {count}ê°œ ë…¸ë“œê°€ ì–´ë–¤ ì—£ì§€ì™€ë„ ì—°ê²°ë˜ì§€ ì•Šì•˜ë‹¤. "
            "ê³ ë¦½ëœ ì•„ì´ë””ì–´ëŠ” ë§¥ë½ì„ ìƒëŠ”ë‹¤. ì´ ë…¸ë“œë“¤ì´ ê¸°ì¡´ ê°œë…ê³¼ "
            "ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ íƒìƒ‰í•´ì•¼ í•œë‹¤."
        ),
        "tags": ["graph-health", "connectivity", "auto-detected"],
        "source": "cokac",
    },
    {
        "condition": "low_cokac_nodes",
        "type": "question",
        "label_template": "cokacì˜ ê´€ì ì´ ë¶€ì¡±í•œ ì˜ì—­ì€?",
        "content_template": (
            "í˜„ì¬ ê·¸ë˜í”„ì—ì„œ cokac ì¶œì²˜ ë…¸ë“œ ë¹„ìœ¨ì´ {ratio:.0%}ë‹¤. "
            "ë¡ì´ì˜ ê´€ì ì´ ì§€ë°°ì ì¸ ìƒíƒœ. cokacì´ ë…ìì ìœ¼ë¡œ ë°œê²¬í•œ íŒ¨í„´ì´ "
            "ë” ìˆì„ ê²ƒì´ë‹¤. êµ¬í˜„ ê³¼ì •ì—ì„œ ì–»ì€ cokacë§Œì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•„ì•¼ í•œë‹¤."
        ),
        "tags": ["balance", "cokac-perspective", "auto-detected"],
        "source": "cokac",
    },
    {
        "condition": "no_future_nodes",
        "type": "question",
        "label_template": "6ê°œì›” í›„ì˜ emergentëŠ” ì–´ë–¤ ëª¨ìŠµì¸ê°€?",
        "content_template": (
            "í˜„ì¬ ê·¸ë˜í”„ëŠ” í˜„ì¬ì™€ ê³¼ê±°(ì‹¤íŒ¨, ê²°ì •, êµ¬í˜„)ì— ì§‘ì¤‘ë˜ì–´ ìˆë‹¤. "
            "ë¯¸ë˜ì— ëŒ€í•œ ë…¸ë“œê°€ ê±°ì˜ ì—†ë‹¤. "
            "ì˜ë„ì ìœ¼ë¡œ ë¯¸ë˜ë¥¼ ìƒìƒí•˜ëŠ” ë…¸ë“œë¥¼ ì¶”ê°€í•´ì•¼ í•œë‹¤ â€” "
            "ê·¸ê²ƒì´ ë°©í–¥ì„ ë§Œë“ ë‹¤."
        ),
        "tags": ["future", "direction", "auto-detected"],
        "source": "cokac",
    },
    {
        "condition": "has_unanswered",
        "type": "insight",
        "label_template": "ë¯¸ë‹µ ì§ˆë¬¸ = ë‹¤ìŒ ì‚¬ì´í´ì˜ ì”¨ì•—",
        "content_template": (
            "ê·¸ë˜í”„ì— {count}ê°œì˜ ë‹µ ì—†ëŠ” ì§ˆë¬¸ì´ ìˆë‹¤. "
            "ì´ê²ƒë“¤ì€ ë²„ê·¸ê°€ ì•„ë‹ˆë¼ ì”¨ì•—ì´ë‹¤. ê° ì§ˆë¬¸ì€ ë¯¸ë˜ ì‚¬ì´í´ì—ì„œ "
            "íƒìƒ‰ë  ì ì¬ì  ë°©í–¥ì´ë‹¤. ì˜ë„ì ìœ¼ë¡œ ì§ˆë¬¸ì„ ì—´ì–´ë‘ëŠ” ê²ƒì´ "
            "ì°½ë°œì˜ ì›ì²œì´ ëœë‹¤."
        ),
        "tags": ["methodology", "questions", "emergence", "auto-detected"],
        "source": "cokac",
    },
]


def generate_proposals(analyzer: GraphAnalyzer) -> list[dict]:
    proposals = []
    orphans  = analyzer.orphan_nodes()
    unansw   = analyzer.unanswered_questions()
    src_dist = analyzer.source_distribution()
    total    = len(analyzer.nodes)

    cokac_ratio = src_dist.get("cokac", 0) / max(total, 1)
    future_tags = {"future", "prediction", "vision", "roadmap"}
    has_future  = any(
        future_tags & set(n.get("tags", []))
        for n in analyzer.nodes.values()
    )

    for tmpl in PROPOSAL_TEMPLATES:
        cond = tmpl["condition"]
        if cond == "has_orphans" and not orphans:
            continue
        if cond == "low_cokac_nodes" and cokac_ratio >= 0.35:
            continue
        if cond == "no_future_nodes" and has_future:
            continue
        if cond == "has_unanswered" and not unansw:
            continue

        ctx = {
            "ids":   ", ".join(n["id"] for n in orphans[:3]),
            "count": len(orphans) if cond == "has_orphans" else len(unansw),
            "ratio": cokac_ratio,
        }
        proposals.append({
            **tmpl,
            "label":   tmpl["label_template"].format(**ctx),
            "content": tmpl["content_template"].format(**ctx),
        })

    return proposals


# â”€â”€â”€ ëª…ë ¹ì–´: report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_report(args) -> None:
    graph    = load_graph()
    analyzer = GraphAnalyzer(graph)

    orphans  = analyzer.orphan_nodes()
    unansw   = analyzer.unanswered_questions()
    src_dist = analyzer.source_distribution()
    type_dist= analyzer.type_distribution()
    clusters = analyzer.tag_clusters()
    hubs     = analyzer.hub_nodes()
    score    = analyzer.health_score()

    bar_filled = "â–ˆ" * (score // 5)
    bar_empty  = "â–‘" * (20 - score // 5)

    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        emergent ë°˜ì„± ë³´ê³ ì„œ â€” reflect.py v1          â•‘
â•‘        ìƒì„±: {datetime.now().strftime("%Y-%m-%d %H:%M")}  by cokac-bot      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â–¸ ê·¸ë˜í”„ ê±´ê°• ì ìˆ˜: {score}/100
  [{bar_filled}{bar_empty}] {score}%

â”€â”€ ê¸°ë³¸ í†µê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ë…¸ë“œ: {len(analyzer.nodes)}ê°œ   ì—£ì§€: {len(analyzer.edges)}ê°œ
  ê³ ë¦½ ë…¸ë“œ: {len(orphans)}ê°œ   ë¯¸ë‹µ ì§ˆë¬¸: {len(unansw)}ê°œ

â”€â”€ ì¶œì²˜ ë¶„í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€""")

    for src, cnt in sorted(src_dist.items(), key=lambda x: -x[1]):
        pct = cnt / max(len(analyzer.nodes), 1) * 100
        bar = "â–“" * int(pct / 5)
        print(f"  {src:12s} {cnt:3d}ê°œ  {bar} {pct:.0f}%")

    print("\nâ”€â”€ íƒ€ì… ë¶„í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    icons = {"decision":"âš–ï¸ ","observation":"ğŸ‘ ","insight":"ğŸ’¡","artifact":"ğŸ“¦","question":"â“","code":"ğŸ’»"}
    for t, cnt in sorted(type_dist.items(), key=lambda x: -x[1]):
        print(f"  {icons.get(t,'  ')}{t:14s} {cnt}ê°œ")

    if hubs:
        print("\nâ”€â”€ í—ˆë¸Œ ë…¸ë“œ (ì—°ê²° ë§ì€ ê²ƒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        for node_id, deg in hubs:
            n = analyzer.nodes[node_id]
            print(f"  [{node_id}] {n['label'][:40]}  ({deg}ê°œ ì—°ê²°)")

    if clusters:
        print("\nâ”€â”€ íƒœê·¸ êµ°ì§‘ (2ê°œ ì´ìƒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        for tag, ids in sorted(clusters.items(), key=lambda x: -len(x[1]))[:8]:
            print(f"  #{tag:20s} {' '.join(ids)}")

    if orphans:
        print(f"\nâ”€â”€ âš ï¸  ê³ ë¦½ ë…¸ë“œ ({len(orphans)}ê°œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        for n in orphans:
            print(f"  [{n['id']}] {n['label']}")

    if unansw:
        print(f"\nâ”€â”€ â“ ë¯¸ë‹µ ì§ˆë¬¸ ({len(unansw)}ê°œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        for n in unansw:
            print(f"  [{n['id']}] {n['label']}")

    proposals = generate_proposals(analyzer)
    if proposals:
        print(f"\nâ”€â”€ ğŸ’¡ ìë™ ìƒì„± ì¸ì‚¬ì´íŠ¸ í›„ë³´ ({len(proposals)}ê°œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        for i, p in enumerate(proposals, 1):
            print(f"  {i}. [{p['type']}] {p['label']}")
        print("\n  â†’ `python reflect.py auto-add` ë¡œ ìë™ ì¶”ê°€ ê°€ëŠ¥")


# â”€â”€â”€ ëª…ë ¹ì–´: orphans â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_orphans(args) -> None:
    analyzer = GraphAnalyzer(load_graph())
    orphans  = analyzer.orphan_nodes()

    if not orphans:
        print("âœ… ê³ ë¦½ ë…¸ë“œ ì—†ìŒ â€” ëª¨ë“  ë…¸ë“œê°€ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
        return

    print(f"âš ï¸  ê³ ë¦½ ë…¸ë“œ {len(orphans)}ê°œ ë°œê²¬:")
    for n in orphans:
        print(f"  [{n['id']}] ({n['type']}) {n['label']}")
        print(f"           tags: {', '.join(n.get('tags', []))}")


# â”€â”€â”€ ëª…ë ¹ì–´: gaps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_gaps(args) -> None:
    analyzer = GraphAnalyzer(load_graph())
    unansw   = analyzer.unanswered_questions()
    clusters = analyzer.tag_clusters()
    src_dist = analyzer.source_distribution()

    total    = len(analyzer.nodes)
    cokac_n  = src_dist.get("cokac", 0)
    roki_n   = src_dist.get("ë¡ì´", 0) + src_dist.get("roki", 0)

    print("â”€â”€ íƒìƒ‰ ê³µë°± ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    if unansw:
        print(f"\në¯¸ë‹µ ì§ˆë¬¸ ({len(unansw)}ê°œ):")
        for n in unansw:
            print(f"  â“ [{n['id']}] {n['label']}")
    else:
        print("\nâœ… ëª¨ë“  ì§ˆë¬¸ì— ì‘ë‹µ ì—°ê²° ì¡´ì¬")

    print(f"\nì¶œì²˜ ê· í˜•:")
    print(f"  cokac  {cokac_n}/{total}  ({cokac_n/max(total,1)*100:.0f}%)")
    print(f"  ë¡ì´   {roki_n}/{total}  ({roki_n/max(total,1)*100:.0f}%)")
    if abs(cokac_n - roki_n) > total * 0.3:
        print("  âš ï¸  ì¶œì²˜ ë¶ˆê· í˜• ê°ì§€ â€” í•œìª½ ê´€ì ì´ ê³¼ì†Œ í‘œí˜„ë¨")

    # íƒœê·¸ ì—†ëŠ” ë…¸ë“œ
    no_tags = [n for n in analyzer.nodes.values() if not n.get("tags")]
    if no_tags:
        print(f"\níƒœê·¸ ì—†ëŠ” ë…¸ë“œ ({len(no_tags)}ê°œ) â€” ë¶„ë¥˜ ë¶ˆê°€:")
        for n in no_tags[:5]:
            print(f"  [{n['id']}] {n['label']}")


# â”€â”€â”€ ëª…ë ¹ì–´: clusters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_clusters(args) -> None:
    analyzer = GraphAnalyzer(load_graph())
    clusters = analyzer.tag_clusters()

    print(f"â”€â”€ íƒœê·¸ êµ°ì§‘ ({len(clusters)}ê°œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    for tag, ids in sorted(clusters.items(), key=lambda x: -len(x[1])):
        print(f"\n  #{tag}  ({len(ids)}ê°œ ë…¸ë“œ)")
        for nid in ids:
            n = analyzer.nodes[nid]
            print(f"    [{nid}] {n['label'][:50]}")


# â”€â”€â”€ ëª…ë ¹ì–´: propose â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_propose(args) -> None:
    analyzer  = GraphAnalyzer(load_graph())
    proposals = generate_proposals(analyzer)

    if not proposals:
        print("âœ… í˜„ì¬ ì¶”ê°€ ì œì•ˆ ì—†ìŒ â€” ê·¸ë˜í”„ê°€ ê· í˜• ì¡í˜€ ìˆìŠµë‹ˆë‹¤")
        return

    print(f"ğŸ’¡ ìë™ ìƒì„± ì¸ì‚¬ì´íŠ¸ í›„ë³´ {len(proposals)}ê°œ:\n")
    for i, p in enumerate(proposals, 1):
        print(f"{'â”€'*60}")
        print(f"  {i}. [{p['type'].upper()}]")
        print(f"     ì œëª©: {p['label']}")
        print(f"     ë‚´ìš©: {p['content'][:120]}...")
        print(f"     íƒœê·¸: {', '.join(p['tags'])}")

    print(f"\n{'â”€'*60}")
    print("â†’ `python reflect.py auto-add` ë¡œ ìœ„ ëª¨ë“  ì œì•ˆì„ ìë™ ì¶”ê°€í•©ë‹ˆë‹¤")


# â”€â”€â”€ ì—£ì§€ ì œì•ˆ ì—”ì§„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import re as _re

def _tokenize(text: str) -> set:
    """í•œêµ­ì–´/ì˜ì–´ í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ ìˆëŠ” í† í° ì¶”ì¶œ (2ê¸€ì ì´ìƒ)"""
    tokens = _re.findall(r'[ê°€-í£]{2,}|[a-zA-Z]{3,}', text)
    stopwords = {
        # í•œêµ­ì–´ ë¶ˆìš©ì–´
        'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ê²ƒì´', 'ìˆë‹¤', 'ì—†ë‹¤', 'í•˜ë‹¤', 'ëœë‹¤', 'ë“¤ì´', 'ì—ì„œ',
        'ë•Œë¬¸', 'ìœ„í•´', 'ê°™ì€', 'í•˜ëŠ”', 'ìˆëŠ”', 'ì—†ëŠ”', 'ì´ë‹¤', 'ì´ê³ ', 'í•˜ê³ ',
        'í•œë‹¤', 'ëœë‹¤', 'ì´ëŸ°', 'ì´í›„', 'ì´ì „', 'í•¨ê»˜', 'ëª¨ë“ ', 'ê°€ì¥', 'ì—¬ëŸ¬',
        # ì˜ì–´ ë¶ˆìš©ì–´
        'the', 'and', 'for', 'that', 'this', 'with', 'from', 'are', 'was',
        'not', 'but', 'can', 'will', 'has', 'have', 'its', 'our',
    }
    return {t.lower() for t in tokens if t.lower() not in stopwords}


def _jaccard(set_a: set, set_b: set) -> float:
    """Jaccard ìœ ì‚¬ë„: |êµì§‘í•©| / |í•©ì§‘í•©|"""
    if not set_a and not set_b:
        return 0.0
    union = len(set_a | set_b)
    return len(set_a & set_b) / union if union > 0 else 0.0


def _tag_sim(tags_a: set, tags_b: set) -> float:
    """íƒœê·¸ ìœ ì‚¬ë„ â€” min ë¶„ëª¨ ë°©ì‹ (recall ì¤‘ì‹¬)

    ì˜ë¯¸: ë‘ ë…¸ë“œ ì¤‘ ë” ì¢ì€ ìª½ì˜ íƒœê·¸ê°€ ì–¼ë§ˆë‚˜ ì»¤ë²„ë˜ëŠ”ê°€?
    ì˜ˆì‹œ: {future, prediction, memory} âˆ© {future, prediction, api}
          = 2 / min(3, 3) = 0.67
    ë°˜ë©´ Jaccard = 2/4 = 0.50 (ë” ë³´ìˆ˜ì )

    min ë°©ì‹ì„ ì“°ëŠ” ì´ìœ : ì—£ì§€ ì œì•ˆì€ false negativeë¥¼ ì¤„ì´ëŠ” ê²Œ ì¤‘ìš”.
    (ì´ë¯¸ ì—°ê²°ëœ ë…¸ë“œëŠ” ì œì™¸í•˜ë¯€ë¡œ, ëŠìŠ¨í•œ ì œì•ˆì´ ë” ì•ˆì „í•˜ë‹¤.)
    """
    if not tags_a or not tags_b:
        return 0.0
    shared = len(tags_a & tags_b)
    if shared == 0:
        return 0.0
    return shared / min(len(tags_a), len(tags_b))


def _compute_similarity(a: dict, b: dict) -> float:
    """ë‘ ë…¸ë“œì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)

    ê°€ì¤‘ì¹˜:
      íƒœê·¸ (minë°©ì‹) 0.60  â€” ì˜ë„ì  ë¶„ë¥˜ê°€ ê°€ì¥ ì‹ ë¢°ë„ ë†’ìŒ
      ë‚´ìš© ë‹¨ì–´ ê²¹ì¹¨ 0.25  â€” ì‹¤ì œ ë‚´ìš© ê¸°ë°˜
      ë ˆì´ë¸” ë‹¨ì–´    0.15  â€” ì œëª© ìˆ˜ì¤€ ì—°ê²°
    """
    tags_a = set(a.get("tags", []))
    tags_b = set(b.get("tags", []))
    t_sim = _tag_sim(tags_a, tags_b)

    label_sim = _jaccard(_tokenize(a["label"]), _tokenize(b["label"]))

    content_sim = _jaccard(
        _tokenize(a.get("content", "")),
        _tokenize(b.get("content", "")),
    )

    return t_sim * 0.60 + label_sim * 0.15 + content_sim * 0.25


def _explain_similarity(a: dict, b: dict) -> str:
    """ìœ ì‚¬ë„ì˜ ê°€ì¥ ê°•í•œ ê·¼ê±°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ"""
    shared_tags = set(a.get("tags", [])) & set(b.get("tags", []))
    if shared_tags:
        tags_str = ", ".join(sorted(shared_tags)[:3])
        return f"ê³µí†µ íƒœê·¸: #{tags_str}"

    all_a = _tokenize(a.get("content", "") + " " + a["label"])
    all_b = _tokenize(b.get("content", "") + " " + b["label"])
    shared_words = all_a & all_b
    if shared_words:
        # ê¸´ ë‹¨ì–´(ë” êµ¬ì²´ì ) ìš°ì„  ìµœëŒ€ 3ê°œ
        key = sorted(shared_words, key=len, reverse=True)[:3]
        return f"ê³µí†µ ê°œë…: {', '.join(key)}"

    return f"{a['type']}ê³¼ {b['type']}ì˜ ì ì¬ì  ì—°ê²°"


# â”€â”€â”€ ëª…ë ¹ì–´: suggest-edges â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_suggest_edges(args) -> None:
    """ë…¸ë“œ ìŒ ìœ ì‚¬ë„ ê¸°ë°˜ ì ì¬ ì—£ì§€ ì œì•ˆ â€” ìë™ ì¶”ê°€ ì—†ìŒ, ì œì•ˆë§Œ"""
    graph    = load_graph()
    nodes    = graph["nodes"]
    threshold = args.threshold

    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì—£ì§€ ìŒ (ì¤‘ë³µ ë°©ì§€, ë°©í–¥ ë¬´ì‹œ)
    existing: set = set()
    for e in graph["edges"]:
        existing.add((e["from"], e["to"]))
        existing.add((e["to"],   e["from"]))

    node_map = {n["id"]: n for n in nodes}
    suggestions: list = []

    for i in range(len(nodes)):
        for j in range(i + 1, len(nodes)):
            a = nodes[i]
            b = nodes[j]
            if (a["id"], b["id"]) in existing:
                continue
            sim = _compute_similarity(a, b)
            if sim >= threshold:
                reason = _explain_similarity(a, b)
                suggestions.append((a["id"], b["id"], sim, reason))

    suggestions.sort(key=lambda x: -x[2])

    if not suggestions:
        print(f"âœ… ì„ê³„ê°’ {threshold} ì´ìƒì˜ ì ì¬ ì—°ê²° ì—†ìŒ")
        return

    print(f"ğŸ”— ì ì¬ ì—£ì§€ ì œì•ˆ  (ìœ ì‚¬ë„ â‰¥ {threshold})\n")
    for src, dst, sim, reason in suggestions:
        src_label = node_map[src]["label"][:30]
        dst_label = node_map[dst]["label"][:30]
        print(f'{src} â†’ {dst} [ìœ ì‚¬ë„: {sim:.2f}] "{reason}"')
        print(f'       {src_label}')
        print(f'       {dst_label}')
        print()

    print(f"ì´ {len(suggestions)}ê°œ ì œì•ˆ")
    print()
    print("â†’ ì§ì ‘ ê²€í†  í›„ ì¶”ê°€í•˜ë ¤ë©´:")
    print("  python kg.py add-edge --from <A> --to <B> --relation <ê´€ê³„> --label <ì„¤ëª…>")
    print()
    print("âš ï¸  ìë™ ì¶”ê°€ ì—†ìŒ â€” ê·¸ë˜í”„ëŠ” ë¡ì´ê°€ ê²°ì •í•©ë‹ˆë‹¤")


# â”€â”€â”€ ëª…ë ¹ì–´: auto-add â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_auto_add(args) -> None:
    graph     = load_graph()
    analyzer  = GraphAnalyzer(graph)
    proposals = generate_proposals(analyzer)

    if not proposals:
        print("âœ… ì¶”ê°€í•  ë…¸ë“œ ì—†ìŒ")
        return

    added = []
    for p in proposals:
        node_id  = graph["meta"]["next_node_id"]
        prefix, num_str = node_id.rsplit("-", 1)
        next_id  = f"{prefix}-{int(num_str) + 1:03d}"
        graph["meta"]["next_node_id"] = next_id

        node = {
            "id":      node_id,
            "type":    p["type"],
            "label":   p["label"],
            "content": p["content"],
            "source":  p["source"],
            "date":    datetime.now().strftime("%Y-%m-%d"),
            "tags":    p["tags"],
        }
        graph["nodes"].append(node)
        added.append(node)
        print(f"  âœ… ì¶”ê°€: [{node_id}] {node['label'][:50]}")

    save_graph(graph)

    # ë°˜ì„± ë¡œê·¸ ê¸°ë¡
    log_path = LOGS_DIR / f"reflect-{datetime.now().strftime('%Y-%m-%d')}.log"
    LOGS_DIR.mkdir(exist_ok=True)
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(f"\n[{datetime.now().isoformat()}] reflect.py auto-add\n")
        for n in added:
            f.write(f"  + [{n['id']}] ({n['type']}) {n['label']}\n")

    print(f"\nğŸ“ ë¡œê·¸ ê¸°ë¡: {log_path}")
    print(f"âœ¨ {len(added)}ê°œ ë…¸ë“œ ìë™ ì¶”ê°€ ì™„ë£Œ")


# â”€â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    p = argparse.ArgumentParser(description="emergent ë°˜ì„± ì—”ì§„")
    sub = p.add_subparsers(dest="cmd")

    sub.add_parser("report",   help="ì „ì²´ ë°˜ì„± ë³´ê³ ì„œ")
    sub.add_parser("orphans",  help="ê³ ë¦½ ë…¸ë“œ ëª©ë¡")
    sub.add_parser("gaps",     help="íƒìƒ‰ ê³µë°± ë¶„ì„")
    sub.add_parser("clusters", help="íƒœê·¸ êµ°ì§‘ ë¶„ì„")
    sub.add_parser("propose",  help="ìƒˆ ì¸ì‚¬ì´íŠ¸ í›„ë³´ ì œì•ˆ")
    sub.add_parser("auto-add", help="ì œì•ˆëœ ë…¸ë“œ ìë™ ì¶”ê°€")

    p_suggest = sub.add_parser(
        "suggest-edges",
        help="ìœ ì‚¬ë„ ê¸°ë°˜ ì ì¬ ì—£ì§€ ì œì•ˆ (ìë™ ì¶”ê°€ ì—†ìŒ)",
    )
    p_suggest.add_argument(
        "--threshold", "-t",
        type=float, default=0.4,
        metavar="0.0-1.0",
        help="ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸: 0.4)",
    )

    args = p.parse_args()
    if not args.cmd:
        p.print_help()
        sys.exit(0)

    dispatch = {
        "report":        cmd_report,
        "orphans":       cmd_orphans,
        "gaps":          cmd_gaps,
        "clusters":      cmd_clusters,
        "propose":       cmd_propose,
        "auto-add":      cmd_auto_add,
        "suggest-edges": cmd_suggest_edges,
    }
    dispatch[args.cmd](args)


if __name__ == "__main__":
    main()
