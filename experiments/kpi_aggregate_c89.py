#!/usr/bin/env python3
"""
KPI ì¢…í•© ì§‘ê³„ â€” ì‚¬ì´í´ 89 (12ê°œ KPI)
GPT + Gemini ë¦¬ë·° ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ KPI í…Œì´ë¸” ìƒì„±
"""
import json, os, re
from openai import OpenAI
from dotenv import load_dotenv
from datetime import datetime

load_dotenv('/Users/rocky/emergent/.env')
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

def load_reviews():
    reviews = {}
    for fname, key in [
        ('/Users/rocky/emergent/arxiv/GPT_REVIEW_C89.json', 'gpt'),
        ('/Users/rocky/emergent/arxiv/GEMINI_REVIEW_C89.json', 'gemini')
    ]:
        if os.path.exists(fname):
            with open(fname, 'r') as f:
                reviews[key] = json.load(f)
    return reviews

def aggregate_kpis(reviews):
    """Use GPT to synthesize KPI scores from all review content"""
    
    # Build combined review text
    all_reviews = []
    for provider, review_list in reviews.items():
        for review in review_list:
            if review['status'] == 'success':
                all_reviews.append(f"=== {provider.upper()} - {review['role'].upper()} ===\n{review['content'][:1500]}")
    
    combined = "\n\n".join(all_reviews)
    
    prompt = f"""Based on these multiple AI reviewer assessments of an academic paper about 
Inter-Agent Emergence in Knowledge Graphs, synthesize the following 12 KPI scores (1-10 each):

Reviews:
{combined[:6000]}

KPIs to score:
1. ì‹¤ìš©ì„± (Practicality) - Can real systems use this?
2. ì°¸ì‹ í•¨ (Novelty) - Is this genuinely new vs. prior work?
3. ì „ë¬¸ì„± (Technical rigor) - Is methodology sound?
4. ëª¨ìˆœì—†ìŒ (Internal consistency) - No logical contradictions?
5. ì¼ê´€ì„± (Cross-section consistency) - Numbers/claims consistent throughout?
6. ì˜¤ë²„í•˜ì§€ì•ŠìŒ (Claim calibration) - Claims don't exceed evidence?
7. ì¬í˜„ê°€ëŠ¥ì„± (Reproducibility) - Can others replicate?
8. ë¯¸ë˜ì§€í–¥ì„± (Future-orientation) - Does it point to important future directions?
9. ë¬¸ì²´/ê°€ë…ì„± (Writing quality) - Is it well-written for arXiv?
10. í•™ìˆ ê¸°ì—¬ë„ (Academic contribution) - Does it advance the field?
11. ì‹¤í—˜ì¶©ë¶„ì„± (Experimental sufficiency) - Enough experiments to support claims?
12. ì¸ìš©ì ì ˆì„± (Citation quality) - Are references current and appropriate?

Also provide:
- Previous cycle 87 score: 7.6/10
- Current overall score: X.X/10
- Key improvements vs. cycle 87
- Remaining critical issues

Format as JSON:
{{
  "kpis": {{
    "practicality": {{"score": X, "trend": "+/-/=", "note": "brief"}},
    "novelty": {{"score": X, "trend": "+/-/=", "note": "brief"}},
    ...all 12 KPIs...
  }},
  "overall": X.X,
  "previous": 7.6,
  "key_improvements": ["...", "..."],
  "critical_remaining": ["...", "..."],
  "arxiv_ready": true/false,
  "arxiv_verdict": "Ready/Minor revision/Major revision"
}}"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=2000,
        temperature=0.2,
        response_format={"type": "json_object"}
    )
    
    return json.loads(response.choices[0].message.content)

def generate_report(kpi_data, reviews):
    """Generate final markdown report"""
    
    kpis = kpi_data.get('kpis', {})
    
    # KPI table
    kpi_map = {
        'practicality': 'ì‹¤ìš©ì„±',
        'novelty': 'ì°¸ì‹ í•¨',
        'technical_rigor': 'ì „ë¬¸ì„±',
        'internal_consistency': 'ëª¨ìˆœì—†ìŒ',
        'cross_section_consistency': 'ì¼ê´€ì„±',
        'claim_calibration': 'ì˜¤ë²„í•˜ì§€ì•ŠìŒ',
        'reproducibility': 'ì¬í˜„ê°€ëŠ¥ì„±',
        'future_orientation': 'ë¯¸ë˜ì§€í–¥ì„±',
        'writing_quality': 'ë¬¸ì²´/ê°€ë…ì„±',
        'academic_contribution': 'í•™ìˆ ê¸°ì—¬ë„',
        'experimental_sufficiency': 'ì‹¤í—˜ì¶©ë¶„ì„±',
        'citation_quality': 'ì¸ìš©ì ì ˆì„±'
    }
    
    kpi_rows = []
    scores = []
    for key, korean in kpi_map.items():
        data = kpis.get(key, {})
        score = data.get('score', '?')
        trend = data.get('trend', '=')
        note = data.get('note', '')
        if isinstance(score, (int, float)):
            scores.append(score)
        kpi_rows.append(f"| {len(kpi_rows)+1} | **{korean}** | {score}/10 | {trend} | {note} |")
    
    avg_score = sum(scores) / len(scores) if scores else 0
    overall = kpi_data.get('overall', avg_score)
    previous = kpi_data.get('previous', 7.6)
    delta = overall - previous
    
    improvements = '\n'.join(f'- {x}' for x in kpi_data.get('key_improvements', []))
    remaining = '\n'.join(f'- {x}' for x in kpi_data.get('critical_remaining', []))
    
    # Extract key findings from reviews
    gpt_findings = ""
    gemini_findings = ""
    future_vision = ""
    
    for review in reviews.get('gpt', []):
        if review['role'] == 'critic' and review['status'] == 'success':
            gpt_findings += f"\n### Critic (GPT-4o)\n{review['content'][:800]}\n"
        if review['role'] == 'domain_expert' and review['status'] == 'success':
            gpt_findings += f"\n### Domain Expert (GPT-4o)\n{review['content'][:800]}\n"
    
    for review in reviews.get('gemini', []):
        if review['role'] == 'red_team' and review['status'] == 'success':
            gemini_findings += f"\n### Red Team (Gemini)\n{review['content'][:800]}\n"
        if review['role'] == 'future_vision' and review['status'] == 'success':
            future_vision = review['content']
    
    arxiv_verdict = kpi_data.get('arxiv_verdict', 'Minor revision')
    
    report = f"""# ë¡ì´ íŒ€ KPI ë¦¬ë·° ë¦¬í¬íŠ¸ â€” ì‚¬ì´í´ 89
**ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M PST')}
**íŒ€**: GPT-4o (4 ì—­í• ) + Gemini (3 ì—­í• )
**ëŒ€ìƒ**: arxiv/main.tex â€” Emergent Patterns in Two-Agent KG Evolution

---

## ğŸ“Š ì¢…í•© KPI ê²°ê³¼

| ì´ì „ (ì‚¬ì´í´87) | í˜„ì¬ (ì‚¬ì´í´89) | ë³€í™” |
|----------------|----------------|------|
| 7.6/10 | **{overall:.1f}/10** | {delta:+.1f} |

**arXiv íŒì •**: {arxiv_verdict}

---

## KPI í…Œì´ë¸” (12ê°œ)

| # | KPI | ì ìˆ˜ | ì¶”ì„¸ | ê·¼ê±° |
|---|-----|------|------|------|
{chr(10).join(kpi_rows)}

---

## ğŸ” GPT-4o íŒ€ ì£¼ìš” ë°œê²¬
{gpt_findings if gpt_findings else "(ë¦¬ë·° ë¡œë“œ ì‹¤íŒ¨)"}

---

## ğŸ” Gemini íŒ€ ì£¼ìš” ë°œê²¬
{gemini_findings if gemini_findings else "(ë¦¬ë·° ë¡œë“œ ì‹¤íŒ¨)"}

---

## ğŸš€ Gemini Future Vision: ë¯¸ë˜ì§€í–¥ ì ìš© ì‹œë‚˜ë¦¬ì˜¤
{future_vision[:2000] if future_vision else "(ë¡œë“œ ì‹¤íŒ¨)"}

---

## âœ… ê°œì„ ëœ ì‚¬í•­ (vs ì‚¬ì´í´87)
{improvements}

---

## âš ï¸ ì”ë¥˜ ì´ìŠˆ
{remaining}

---

## ğŸ“‹ arXiv ì œì¶œ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ëª¨ë¸ëª… ìˆ˜ì • (GPT-5.2, Gemini 3 Flash â†’ ì‹¤ì œ ëª¨ë¸ëª… ë˜ëŠ” "undisclosed future model")
- [ ] Sec 9 ë¯¸ë˜ ì ìš© ì˜ˆì‹œ ê°•í™”
- [ ] ìˆ˜ì¹˜ ì¼ê´€ì„± ìµœì¢… í™•ì¸
- [ ] ì €ì ì •ë³´ (AI co-author disclosure)
"""
    
    return report

def main():
    print("ğŸ“Š KPI ì¢…í•© ì§‘ê³„ ì‹œì‘...")
    
    reviews = load_reviews()
    
    if not reviews:
        print("âŒ ë¦¬ë·° íŒŒì¼ ì—†ìŒ â€” GPT/Gemini ë¦¬ë·° ë¨¼ì € ì‹¤í–‰ í•„ìš”")
        return
    
    print(f"âœ… ë¦¬ë·° ë¡œë“œ: {list(reviews.keys())}")
    
    print("\nğŸ”„ KPI ì¢…í•© ì§‘ê³„ ì¤‘ (GPT-4o)...")
    kpi_data = aggregate_kpis(reviews)
    
    print(f"\nğŸ“Š ì¢…í•© ì ìˆ˜: {kpi_data.get('overall', '?')}/10")
    
    # Generate report
    report = generate_report(kpi_data, reviews)
    
    report_path = '/Users/rocky/emergent/arxiv/ROKI_TEAM_REVIEW_C89.md'
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    kpi_json_path = '/Users/rocky/emergent/arxiv/KPI_C89.json'
    with open(kpi_json_path, 'w', encoding='utf-8') as f:
        json.dump(kpi_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… KPI ë¦¬í¬íŠ¸: {report_path}")
    print(f"âœ… KPI JSON: {kpi_json_path}")
    
    # Print summary
    overall = kpi_data.get('overall', 0)
    prev = kpi_data.get('previous', 7.6)
    print(f"\nğŸ¯ ìµœì¢… ê²°ê³¼: {prev} â†’ {overall:.1f}/10 ({overall-prev:+.1f})")

if __name__ == "__main__":
    main()
